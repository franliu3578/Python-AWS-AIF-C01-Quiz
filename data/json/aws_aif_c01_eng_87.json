[
    {
        "question": "An AI practitioner trained a custom model on Amazon Bedrock by using a training dataset that contains confidential data. The AI practitioner wants to ensure that the custom model does not generate inference responses based on confidential data. How should the AI practitioner prevent responses based on confidential data?",
        "options": [
            "A. Delete the custom model. Remove the confidential data from the training dataset. Retrain the custom model.",
            "B. Mask the confidential data in the inference responses by using dynamic data masking.",
            "C. Encrypt the confidential data in the inference responses by using Amazon SageMaker.",
            "D. Encrypt the confidential data in the custom model by using AWS Key Management Service (AWS KMS)."
        ],
        "answer": "A. Delete the custom model. Remove the confidential data from the training dataset. Retrain the custom model.",
        "keywords": ["Amazon Bedrock", "confidential data", "prevent responses"],
        "explanation": "Deleting the custom model and retraining it without confidential data ensures no sensitive information is included in inference outputs."
    },
    {
        "question": "Which feature of Amazon OpenSearch Service gives companies the ability to build vector database applications?",
        "options": [
            "A. Integration with Amazon S3 for object storage",
            "B. Support for geospatial indexing and queries",
            "C. Scalable index management and nearest neighbor search capability",
            "D. Ability to perform real-time analysis on streaming data"
        ],
        "answer": "C. Scalable index management and nearest neighbor search capability",
        "keywords": ["Amazon OpenSearch", "vector database", "nearest neighbor search"],
        "explanation": "This feature enables efficient storage and retrieval for vector database applications, crucial for search and recommendation systems."
    },
    {
        "question": "A company wants to display the total sales for its top-selling products across various retail locations in the past 12 months. Which AWS solution should the company use to automate the generation of graphs?",
        "options": [
            "A. Amazon Q in Amazon EC2",
            "B. Amazon Q Developer",
            "C. Amazon Q in Amazon QuickSight",
            "D. Amazon Q in AWS Chatbot"
        ],
        "answer": "C. Amazon Q in Amazon QuickSight",
        "keywords": ["total sales", "top-selling products", "graphs"],
        "explanation": "Amazon QuickSight automates data visualization, making it the optimal choice for generating graphs for sales data."
    },
    {
        "question": "A company wants to build an interactive application for children that generates new stories based on classic stories. The company wants to use Amazon Bedrock and needs to ensure that the results and topics are appropriate for children. Which AWS service or feature will meet these requirements?",
        "options": [
            "A. Amazon Rekognition",
            "B. Amazon Bedrock playgrounds",
            "C. Guardrails for Amazon Bedrock",
            "D. Agents for Amazon Bedrock"
        ],
        "answer": "C. Guardrails for Amazon Bedrock",
        "keywords": ["interactive application", "children", "appropriate topics"],
        "explanation": "Guardrails ensure the generated content aligns with desired standards, especially for sensitive audiences like children."
    },
    {
        "question": "A company has developed an ML model for image classification. The company wants to deploy the model to production so that a web application can use the model. The company needs to implement a solution to host the model and serve predictions without managing any of the underlying infrastructure. Which solution will meet these requirements?",
        "options": [
            "A. Use Amazon SageMaker Serverless Inference to deploy the model.",
            "B. Use Amazon CloudFront to deploy the model.",
            "C. Use Amazon API Gateway to host the model and serve predictions.",
            "D. Use AWS Batch to host the model and serve predictions."
        ],
        "answer": "A. Use Amazon SageMaker Serverless Inference to deploy the model.",
        "keywords": ["ML model", "image classification", "host predictions"],
        "explanation": "Serverless Inference in SageMaker allows deployment without managing servers, ideal for production ML workloads."
    },
    {
        "question": "A company has petabytes of unlabeled customer data to use for an advertisement campaign. The company wants to classify its customers into tiers to advertise and promote the company's products. Which methodology should the company use to meet these requirements?",
        "options": [
            "A. Supervised learning",
            "B. Unsupervised learning",
            "C. Reinforcement learning",
            "D. Reinforcement learning from human feedback (RLHF)"
        ],
        "answer": "B. Unsupervised learning",
        "keywords": ["unlabeled data", "classify customers", "advertisement campaign"],
        "explanation": "Unsupervised learning identifies patterns in unlabeled data, making it suitable for tier classification."
    },
    {
        "question": "A company makes forecasts each quarter to decide how to optimize operations to meet expected demand. The company uses ML models to make these forecasts. An AI practitioner is writing a report about the trained ML models to provide transparency and explainability to company stakeholders. What should the AI practitioner include in the report to meet the transparency and explainability requirements?",
        "options": [
            "A. Code for model training",
            "B. Partial dependence plots (PDPs)",
            "C. Sample data for training",
            "D. Model convergence tables"
        ],
        "answer": "B. Partial dependence plots (PDPs)",
        "keywords": ["transparency", "explainability", "ML forecasts"],
        "explanation": "Partial dependence plots visually explain the influence of input features on predictions, enhancing stakeholder understanding."
    },
    {
        "question": "Which option is a use case for generative AI models?",
        "options": [
            "A. Improving network security by using intrusion detection systems",
            "B. Creating photorealistic images from text descriptions for digital marketing",
            "C. Enhancing database performance by using optimized indexing",
            "D. Analyzing financial data to forecast stock market trends"
        ],
        "answer": "B. Creating photorealistic images from text descriptions for digital marketing",
        "keywords": ["generative AI", "photorealistic images", "marketing"],
        "explanation": "Generative AI models excel at creating realistic content like images, aiding digital marketing efforts."
    },
    {
        "question": "An AI practitioner is using a large language model (LLM) to create content for marketing campaigns. The generated content sounds plausible and factual but is incorrect. Which problem is the LLM having?",
        "options": [
            "A. Data leakage",
            "B. Hallucination",
            "C. Overfitting",
            "D. Underfitting"
        ],
        "answer": "B. Hallucination",
        "keywords": ["LLM", "plausible content", "incorrect"],
        "explanation": "Hallucination refers to AI generating confident but incorrect information, common in LLM outputs."
    },
    {
        "question": "A loan company is building a generative AI-based solution to offer new applicants discounts based on specific business criteria. The company wants to build and use an AI model responsibly to minimize bias that could negatively affect some customers. Which actions should the company take to meet these requirements? (Select TWO.)",
        "options": [
            "A. Detect imbalances or disparities in the data.",
            "B. Ensure that the model runs frequently.",
            "C. Evaluate the model's behavior so that the company can provide transparency to stakeholders.",
            "D. Use the Recall-Oriented Understudy for Gisting Evaluation (ROUGE) technique to ensure that the model is 100% accurate.",
            "E. Ensure that the model's inference time is within the accepted limits."
        ],
        "answer": [
            "A. Detect imbalances or disparities in the data.",
            "C. Evaluate the model's behavior so that the company can provide transparency to stakeholders."
        ],
        "keywords": ["generative AI", "bias", "responsible AI"],
        "explanation": "Detecting data imbalances and evaluating model behavior are critical for building responsible AI solutions."
    },
    {
        "question": "A medical company is customizing a foundation model (FM) for diagnostic purposes. The company needs the model to be transparent and explainable to meet regulatory requirements. Which solution will meet these requirements?",
        "options": [
            "A. Configure the security and compliance by using Amazon Inspector.",
            "B. Generate simple metrics, reports, and examples by using Amazon SageMaker Clarify.",
            "C. Encrypt and secure training data by using Amazon Macie.",
            "D. Gather more data. Use Amazon Rekognition to add custom labels to the data."
        ],
        "answer": "B. Generate simple metrics, reports, and examples by using Amazon SageMaker Clarify.",
        "keywords": ["diagnostic purposes", "transparent", "explainable", "SageMaker Clarify"],
        "explanation": "Amazon SageMaker Clarify generates metrics and examples to ensure transparency and explainability, which are crucial for regulatory compliance."
    },
    {
        "question": "A company is building a solution to generate images for protective eyewear. The solution must have high accuracy and must minimize the risk of incorrect annotations. Which solution will meet these requirements?",
        "options": [
            "A. Human-in-the-loop validation by using Amazon SageMaker Ground Truth Plus",
            "B. Data augmentation by using an Amazon Bedrock knowledge base",
            "C. Image recognition by using Amazon Rekognition",
            "D. Data summarization by using Amazon QuickSight"
        ],
        "answer": "A. Human-in-the-loop validation by using Amazon SageMaker Ground Truth Plus",
        "keywords": ["protective eyewear", "high accuracy", "incorrect annotations"],
        "explanation": "Human-in-the-loop validation ensures the quality of annotations, reducing risks in the image generation process."
    },
    {
        "question": "A security company is using Amazon Bedrock to run foundation models (FMs). The company wants to ensure that only authorized users invoke the models. The company needs to identify any unauthorized access attempts to set appropriate AWS Identity and Access Management (IAM) policies and roles for future iterations of the FMs. Which AWS service should the company use to identify unauthorized users that are trying to access Amazon Bedrock?",
        "options": [
            "A. AWS Audit Manager",
            "B. AWS CloudTrail",
            "C. Amazon Fraud Detector",
            "D. AWS Trusted Advisor"
        ],
        "answer": "B. AWS CloudTrail",
        "keywords": ["Amazon Bedrock", "unauthorized users", "IAM policies", "AWS CloudTrail"],
        "explanation": "AWS CloudTrail logs API activity, enabling the company to monitor and identify unauthorized access attempts."
    },
    {
        "question": "A company manually reviews all submitted resumes in PDF format. As the company grows, the company expects the volume of resumes to exceed the company's review capacity. The company needs an automated system to convert the PDF resumes into plain text format for additional processing. Which AWS service meets this requirement?",
        "options": [
            "A. Amazon Textract",
            "B. Amazon Personalize",
            "C. Amazon Lex",
            "D. Amazon Transcribe"
        ],
        "answer": "A. Amazon Textract",
        "keywords": ["PDF resumes", "plain text", "automated system"],
        "explanation": "Amazon Textract extracts text from documents, making it ideal for automating resume processing."
    },
    {
        "question": "A company wants to use large language models (LLMs) with Amazon Bedrock to develop a chat interface for the company's product manuals. The manuals are stored as PDF files. Which solution meets these requirements MOST cost-effectively?",
        "options": [
            "A. Use prompt engineering to add one PDF file as context to the user prompt when the prompt is submitted to Amazon Bedrock.",
            "B. Use prompt engineering to add all the PDF files as context to the user prompt when the prompt is submitted to Amazon Bedrock.",
            "C. Use all the PDF documents to fine-tune a model with Amazon Bedrock. Use the fine-tuned model to process user prompts.",
            "D. Upload PDF documents to an Amazon Bedrock knowledge base. Use the knowledge base to provide context when users submit prompts to Amazon Bedrock."
        ],
        "answer": "D. Upload PDF documents to an Amazon Bedrock knowledge base. Use the knowledge base to provide context when users submit prompts to Amazon Bedrock.",
        "keywords": ["Amazon Bedrock", "PDF files", "knowledge base", "cost-effective"],
        "explanation": "Using a knowledge base in Amazon Bedrock is more cost-effective than fine-tuning or processing all files in real-time."
    },
    {
        "question": "Which term describes the numerical representations of real-world objects and concepts that AI and natural language processing (NLP) models use to improve understanding of textual information?",
        "options": [
            "A. Embeddings",
            "B. Tokens",
            "C. Models",
            "D. Binaries"
        ],
        "answer": "A. Embeddings",
        "keywords": ["numerical representations", "AI", "NLP", "textual information"],
        "explanation": "Embeddings are mathematical representations that improve AI models' ability to understand and process text."
    },
    {
        "question": "A company is building an application that needs to generate synthetic data that is based on existing data. Which type of model can the company use to meet this requirement?",
        "options": [
            "A. Generative adversarial network (GAN)",
            "B. XGBoost",
            "C. Residual neural network",
            "D. WaveNet"
        ],
        "answer": "A. Generative adversarial network (GAN)",
        "keywords": ["synthetic data", "existing data", "GAN"],
        "explanation": "Generative adversarial networks are widely used for generating synthetic data by training two neural networks in competition."
    },
    {
        "question": "A company wants to use generative AI to increase developer productivity and software development. The company wants to use Amazon Q Developer. What can Amazon Q Developer do to help the company meet these requirements?",
        "options": [
            "A. Create software snippets, reference tracking, and open-source license tracking.",
            "B. Run an application without provisioning or managing servers.",
            "C. Enable voice commands for coding and providing natural language search.",
            "D. Convert audio files to text documents by using ML models."
        ],
        "answer": "C. Enable voice commands for coding and providing natural language search.",
        "keywords": ["generative AI", "developer productivity", "Amazon Q Developer"],
        "explanation": "Amazon Q Developer uses generative AI to enable natural language interactions, improving developer efficiency."
    },
    {
        "question": "A company wants to create an application by using Amazon Bedrock. The company has a limited budget and prefers flexibility without long-term commitment. Which Amazon Bedrock pricing model meets these requirements?",
        "options": [
            "A. On-Demand",
            "B. Model customization",
            "C. Provisioned Throughput",
            "D. Spot Instance"
        ],
        "answer": "A. On-Demand",
        "keywords": ["Amazon Bedrock", "pricing model", "flexibility", "limited budget"],
        "explanation": "On-Demand pricing provides flexibility without requiring long-term commitments, making it ideal for budget-conscious applications."
    },
    {
        "question": "A digital devices company wants to predict customer demand for memory hardware. The company does not have coding experience or knowledge of ML algorithms and needs to develop a data-driven predictive model. The company needs to perform analysis on internal data and external data. Which solution will meet these requirements?",
        "options": [
            "A. Store the data in Amazon S3. Create ML models and demand forecast predictions by using Amazon SageMaker built-in algorithms that use the data from Amazon S3.",
            "B. Import the data into Amazon SageMaker Data Wrangler. Create ML models and demand forecast predictions by using SageMaker built-in algorithms.",
            "C. Import the data into Amazon SageMaker Data Wrangler. Build ML models and demand forecast predictions by using an Amazon Personalize Trending-Now recipe.",
            "D. Import the data into Amazon SageMaker Canvas. Build ML models and demand forecast predictions by selecting the values in the data from SageMaker Canvas."
        ],
        "answer": "D. Import the data into Amazon SageMaker Canvas. Build ML models and demand forecast predictions by selecting the values in the data from SageMaker Canvas.",
        "keywords": ["predictive model", "customer demand", "SageMaker Canvas"],
        "explanation": "SageMaker Canvas allows non-technical users to build predictive models without requiring coding skills, leveraging internal and external data."
    },
    {
        "question": "What are tokens in the context of generative AI models?",
        "options": [
            "A. Tokens are the basic units of input and output that a generative AI model operates on, representing words, subwords, or other linguistic units.",
            "B. Tokens are the mathematical representations of words or concepts used in generative AI models.",
            "C. Tokens are the pre-trained weights of a generative AI model that are fine-tuned for specific tasks.",
            "D. Tokens are the specific prompts or instructions given to a generative AI model to generate output."
        ],
        "answer": "A. Tokens are the basic units of input and output that a generative AI model operates on, representing words, subwords, or other linguistic units.",
        "keywords": ["generative AI", "tokens", "linguistic units"],
        "explanation": "Tokens represent the smallest units of text that a generative AI model processes, such as words or subwords."
    },
    {
        "question": "An AI practitioner is using an Amazon Bedrock base model to summarize session chats from the customer service department. The AI practitioner wants to store invocation logs to monitor model input and output data. Which strategy should the AI practitioner use?",
        "options": [
            "A. Configure AWS CloudTrail as the logs destination for the model.",
            "B. Enable invocation logging in Amazon Bedrock.",
            "C. Configure AWS Audit Manager as the logs destination for the model.",
            "D. Configure model invocation logging in Amazon EventBridge."
        ],
        "answer": "B. Enable invocation logging in Amazon Bedrock.",
        "keywords": ["Amazon Bedrock", "invocation logs", "monitor input and output"],
        "explanation": "Amazon Bedrock supports invocation logging directly, allowing users to track input and output data for monitoring and compliance."
    },
    {
        "question": "A company needs to build its own large language model (LLM) based on only the company's private data. The company is concerned about the environmental effect of the training process. Which Amazon EC2 instance type has the LEAST environmental effect when training LLMs?",
        "options": [
            "A. Amazon EC2 C series",
            "B. Amazon EC2 G series",
            "C. Amazon EC2 P series",
            "D. Amazon EC2 Trn series"
        ],
        "answer": "D. Amazon EC2 Trn series",
        "keywords": ["LLM training", "EC2 instances", "environmental impact"],
        "explanation": "The Amazon EC2 Trn series instances are designed for efficient ML model training and have the lowest environmental impact."
    },
    {
        "question": "A financial institution is using Amazon Bedrock to develop an AI application. The application is hosted in a VPC. To meet regulatory compliance standards, the VPC is not allowed access to any internet traffic. Which AWS service or feature will meet these requirements?",
        "options": [
            "A. AWS PrivateLink",
            "B. Amazon Macie",
            "C. Amazon CloudFront",
            "D. Internet gateway"
        ],
        "answer": "A. AWS PrivateLink",
        "keywords": ["Amazon Bedrock", "VPC", "regulatory compliance", "internet traffic"],
        "explanation": "AWS PrivateLink allows secure access to services without internet connectivity, meeting compliance requirements."
    },
    {
        "question": "A company built a deep learning model for object detection and deployed the model to production. Which AI process occurs when the model analyzes a new image to identify objects?",
        "options": [
            "A. Training",
            "B. Inference",
            "C. Model deployment",
            "D. Bias correction"
        ],
        "answer": "B. Inference",
        "keywords": ["deep learning", "object detection", "inference"],
        "explanation": "Inference refers to the process of analyzing new data using a trained model to make predictions or identify patterns."
    },
    {
        "question": "A company is using Amazon SageMaker Studio notebooks to build and train ML models. The company stores the data in an Amazon S3 bucket. The company needs to manage the flow of data from Amazon S3 to SageMaker Studio notebooks. Which solution will meet this requirement?",
        "options": [
            "A. Use Amazon Inspector to monitor SageMaker Studio.",
            "B. Use Amazon Macie to monitor SageMaker Studio.",
            "C. Configure SageMaker to use a VPC with an S3 endpoint.",
            "D. Configure SageMaker to use S3 Glacier Deep Archive."
        ],
        "answer": "C. Configure SageMaker to use a VPC with an S3 endpoint.",
        "keywords": ["SageMaker Studio", "S3 endpoint", "data flow management"],
        "explanation": "Using a VPC with an S3 endpoint ensures secure and efficient data flow between Amazon S3 and SageMaker Studio."
    },
    {
        "question": "A company is using domain-specific models. The company wants to avoid creating new models from the beginning. The company instead wants to adapt pre-trained models to create models for new, related tasks. Which ML strategy meets these requirements?",
        "options": [
            "A. Increase the number of epochs.",
            "B. Use transfer learning.",
            "C. Decrease the number of epochs.",
            "D. Use unsupervised learning."
        ],
        "answer": "B. Use transfer learning.",
        "keywords": ["domain-specific models", "pre-trained models", "transfer learning"],
        "explanation": "Transfer learning allows leveraging pre-trained models to adapt them for new, related tasks, saving time and resources."
    },
    {
        "question": "A company wants to use AI to protect its application from threats. The AI solution needs to check if an IP address is from a suspicious source. Which solution meets these requirements?",
        "options": [
            "A. Build a speech recognition system.",
            "B. Create a natural language processing (NLP) named entity recognition system.",
            "C. Develop an anomaly detection system.",
            "D. Create a fraud forecasting system."
        ],
        "answer": "C. Develop an anomaly detection system.",
        "keywords": ["AI security", "IP address threats", "anomaly detection"],
        "explanation": "Anomaly detection systems identify patterns in data that deviate from expected behavior, ideal for detecting suspicious IP addresses."
    },
    {
        "question": "A company wants to use a large language model (LLM) to develop a conversational agent. The company needs to prevent the LLM from being manipulated with common prompt engineering techniques to perform undesirable actions or expose sensitive information. Which action will reduce these risks?",
        "options": [
            "A. Create a prompt template that teaches the LLM to detect attack patterns.",
            "B. Increase the temperature parameter on invocation requests to the LLM.",
            "C. Avoid using LLMs that are not listed in Amazon SageMaker.",
            "D. Decrease the number of input tokens on invocations of the LLM."
        ],
        "answer": "A. Create a prompt template that teaches the LLM to detect attack patterns.",
        "keywords": ["LLM", "security", "prompt engineering"],
        "explanation": "Prompt templates designed to detect attack patterns reduce the risk of manipulation and enhance security."
    },
    {
        "question": "A company is developing a new model to predict the prices of specific items. The model performed well on the training dataset. When the company deployed the model to production, the model's performance decreased significantly. What should the company do to mitigate this problem?",
        "options": [
            "A. Reduce the volume of data that is used in training.",
            "B. Add hyperparameters to the model.",
            "C. Increase the volume of data that is used in training.",
            "D. Increase the model training time."
        ],
        "answer": "C. Increase the volume of data that is used in training.",
        "keywords": ["model performance", "training data", "production environment"],
        "explanation": "Increasing the training data volume improves the model's ability to generalize, reducing performance degradation in production."
    },
    {
        "question": "A company wants to create a chatbot by using a foundation model (FM) on Amazon Bedrock. The FM needs to access encrypted data that is stored in an Amazon S3 bucket. The data is encrypted with Amazon S3 managed keys (SSE-S3). The FM encounters a failure when attempting to access the S3 bucket data. Which solution will meet these requirements?",
        "options": [
            "A. Ensure that the role that Amazon Bedrock assumes has permission to decrypt data with the correct encryption key.",
            "B. Set the access permissions for the S3 buckets to allow public access to enable access over the internet.",
            "C. Use prompt engineering techniques to tell the model to look for information in Amazon S3.",
            "D. Ensure that the S3 data does not contain sensitive information."
        ],
        "answer": "A. Ensure that the role that Amazon Bedrock assumes has permission to decrypt data with the correct encryption key.",
        "keywords": ["Amazon Bedrock", "S3 encryption", "SSE-S3"],
        "explanation": "To access encrypted data, the role assumed by Amazon Bedrock must have the necessary permissions to decrypt the data using the correct encryption key."
    },
    {
        "question": "A company has a foundation model (FM) that was customized by using Amazon Bedrock to answer customer queries about products. The company wants to validate the model's responses to new types of queries. The company needs to upload a new dataset that Amazon Bedrock can use for validation. Which AWS service meets these requirements?",
        "options": [
            "A. Amazon S3",
            "B. Amazon Elastic Block Store (Amazon EBS)",
            "C. Amazon Elastic File System (Amazon EFS)",
            "D. AWS Snowcone"
        ],
        "answer": "A. Amazon S3",
        "keywords": ["Amazon Bedrock", "validation", "dataset upload"],
        "explanation": "Amazon S3 is used for storing datasets and making them accessible for validation or training purposes."
    },
    {
        "question": "A company wants to assess the costs that are associated with using a large language model (LLM) to generate inferences. The company wants to use Amazon Bedrock to build generative AI applications. Which factor will drive the inference costs?",
        "options": [
            "A. Number of tokens consumed",
            "B. Temperature value",
            "C. Amount of data used to train the LLM",
            "D. Total training time"
        ],
        "answer": "A. Number of tokens consumed",
        "keywords": ["LLM", "Amazon Bedrock", "inference costs"],
        "explanation": "Inference costs are primarily driven by the number of tokens consumed during the input and output processing of the model."
    },
    {
        "question": "An AI company periodically evaluates its systems and processes with the help of independent software vendors (ISVs). The company needs to receive email message notifications when an ISV's compliance reports become available. Which AWS service can the company use to meet this requirement?",
        "options": [
            "A. AWS Audit Manager",
            "B. AWS Artifact",
            "C. AWS Trusted Advisor",
            "D. AWS Data Exchange"
        ],
        "answer": "B. AWS Artifact",
        "keywords": ["compliance", "ISV reports", "notifications"],
        "explanation": "AWS Artifact provides access to compliance-related reports and can notify users when new reports are available."
    },
    {
        "question": "A company wants to use a large language model (LLM) on Amazon Bedrock for sentiment analysis. The company needs the LLM to produce more consistent responses to the same input prompt. Which adjustment to an inference parameter should the company make to meet these requirements?",
        "options": [
            "A. Decrease the temperature value",
            "B. Increase the temperature value",
            "C. Decrease the length of output tokens",
            "D. Increase the maximum generation length"
        ],
        "answer": "A. Decrease the temperature value",
        "keywords": ["LLM", "sentiment analysis", "temperature"],
        "explanation": "Decreasing the temperature value makes the model produce more deterministic and consistent responses."
    },
    {
        "question": "A company is implementing the Amazon Titan foundation model (FM) by using Amazon Bedrock. The company needs to supplement the model by using relevant data from the company's private data sources. Which solution will meet this requirement?",
        "options": [
            "A. Use a different FM",
            "B. Choose a lower temperature value",
            "C. Create an Amazon Bedrock knowledge base",
            "D. Enable model invocation logging"
        ],
        "answer": "C. Create an Amazon Bedrock knowledge base",
        "keywords": ["Amazon Titan", "private data", "knowledge base"],
        "explanation": "Creating a knowledge base allows the Amazon Titan FM to incorporate and utilize private data sources effectively."
    },
    {
        "question": "A company wants to develop an educational game where users answer questions such as the following: 'A jar contains six red, four green, and three yellow marbles. What is the probability of choosing a green marble from the jar?' Which solution meets these requirements with the LEAST operational overhead?",
        "options": [
            "A. Use supervised learning to create a regression model that will predict probability.",
            "B. Use reinforcement learning to train a model to return the probability.",
            "C. Use code that will calculate probability by using simple rules and computations.",
            "D. Use unsupervised learning to create a model that will estimate probability density."
        ],
        "answer": "C. Use code that will calculate probability by using simple rules and computations.",
        "keywords": ["educational game", "probability", "operational overhead"],
        "explanation": "Using simple rules and computations is the most efficient solution with the least operational overhead."
    },
    {
        "question": "Which functionality does Amazon SageMaker Clarify provide?",
        "options": [
            "A. Integrates a Retrieval Augmented Generation (RAG) workflow",
            "B. Monitors the quality of ML models in production",
            "C. Documents critical details about ML models",
            "D. Identifies potential bias during data preparation"
        ],
        "answer": "D. Identifies potential bias during data preparation",
        "keywords": ["Amazon SageMaker Clarify", "bias detection", "data preparation"],
        "explanation": "Amazon SageMaker Clarify is specifically designed to detect bias in data preparation and throughout the ML workflow."
    },
    {
        "question": "A company is building an ML model. The company collected new data and analyzed the data by creating a correlation matrix, calculating statistics, and visualizing the data. Which stage of the ML pipeline is the company currently in?",
        "options": [
            "A. Data pre-processing",
            "B. Feature engineering",
            "C. Exploratory data analysis",
            "D. Hyperparameter tuning"
        ],
        "answer": "C. Exploratory data analysis",
        "keywords": ["ML pipeline", "correlation matrix", "statistics", "data visualization"],
        "explanation": "Exploratory data analysis (EDA) is the stage where data is analyzed to discover patterns, spot anomalies, and visualize key relationships."
    },
    {
        "question": "A company has documents that are missing some words because of a database error. The company wants to build an ML model that can suggest potential words to fill in the missing text. Which type of model meets this requirement?",
        "options": [
            "A. Topic modeling",
            "B. Clustering models",
            "C. Prescriptive ML models",
            "D. BERT-based models"
        ],
        "answer": "D. BERT-based models",
        "keywords": ["missing words", "suggest text", "BERT"],
        "explanation": "BERT is a transformer-based model designed for natural language processing tasks like text prediction and completion."
    },
    {
        "question": "A company is building a chatbot to improve user experience. The company is using a large language model (LLM) from Amazon Bedrock for intent detection. The company wants to use few-shot learning to improve intent detection accuracy. Which additional data does the company need to meet these requirements?",
        "options": [
            "A. Pairs of chatbot responses and correct user intents",
            "B. Pairs of user messages and correct chatbot responses",
            "C. Pairs of user messages and correct user intents",
            "D. Pairs of user intents and correct chatbot responses"
        ],
        "answer": "C. Pairs of user messages and correct user intents",
        "keywords": ["LLM", "intent detection", "few-shot learning"],
        "explanation": "Few-shot learning improves model performance with a small number of examples. Providing user messages with corresponding intents is essential."
    },
    {
        "question": "A company is building a large language model (LLM) question answering chatbot. The company wants to decrease the number of actions call center employees need to take to respond to customer questions. Which business objective should the company use to evaluate the effect of the LLM chatbot?",
        "options": [
            "A. Website engagement rate",
            "B. Average call duration",
            "C. Corporate social responsibility",
            "D. Regulatory compliance"
        ],
        "answer": "B. Average call duration",
        "keywords": ["LLM chatbot", "business objective", "call duration"],
        "explanation": "Reducing the average call duration is a key metric to measure the effectiveness of a chatbot in improving efficiency."
    },
    {
        "question": "A company is using few-shot prompting on a base model that is hosted on Amazon Bedrock. The model currently uses 10 examples in the prompt. The model is invoked once daily and is performing well. The company wants to lower the monthly cost. Which solution will meet these requirements?",
        "options": [
            "A. Customize the model by using fine-tuning.",
            "B. Decrease the number of tokens in the prompt.",
            "C. Increase the number of tokens in the prompt.",
            "D. Use Provisioned Throughput."
        ],
        "answer": "B. Decrease the number of tokens in the prompt.",
        "keywords": ["few-shot prompting", "Amazon Bedrock", "cost reduction"],
        "explanation": "Reducing the number of tokens in a prompt decreases the cost associated with model invocation while maintaining performance."
    },
    {
        "question": "An accounting firm wants to implement a large language model (LLM) to automate document processing. The firm must proceed responsibly to avoid potential harms. What should the firm do when developing and deploying the LLM? (Select TWO.)",
        "options": [
            "A. Include fairness metrics for model evaluation.",
            "B. Adjust the temperature parameter of the model.",
            "C. Modify the training data to mitigate bias.",
            "D. Avoid overfitting on the training data.",
            "E. Apply prompt engineering techniques."
        ],
        "answer": ["A. Include fairness metrics for model evaluation.", "C. Modify the training data to mitigate bias."],
        "keywords": ["LLM", "responsible AI", "bias mitigation", "fairness metrics"],
        "explanation": "Including fairness metrics and modifying training data are critical steps to ensure responsible AI deployment and minimize potential harms."
    },
    {
        "question": "A company has built an image classification model to predict plant diseases from photos of plant leaves. The company wants to evaluate how many images the model classified correctly. Which evaluation metric should the company use to measure the model's performance?",
        "options": [
            "A. R-squared score",
            "B. Accuracy",
            "C. Root mean squared error (RMSE)",
            "D. Learning rate"
        ],
        "answer": "B. Accuracy",
        "keywords": ["image classification", "evaluation metric", "accuracy"],
        "explanation": "Accuracy measures the proportion of correct predictions made by the model, making it suitable for evaluating classification tasks."
    },
    {
        "question": "A large retailer receives thousands of customer support inquiries about products every day. The customer support inquiries need to be processed and responded to quickly. The company wants to implement Agents for Amazon Bedrock. What are the key benefits of using Amazon Bedrock agents that could help this retailer?",
        "options": [
            "A. Generation of custom foundation models (FMs) to predict customer needs",
            "B. Automation of repetitive tasks and orchestration of complex workflows",
            "C. Automatically calling multiple foundation models (FMs) and consolidating the results",
            "D. Selecting the foundation model (FM) based on predefined criteria and metrics"
        ],
        "answer": "B. Automation of repetitive tasks and orchestration of complex workflows",
        "keywords": ["Amazon Bedrock", "customer support", "automation", "workflows"],
        "explanation": "Amazon Bedrock agents streamline customer support by automating repetitive tasks and managing complex workflows."
    },
    {
        "question": "A company is training a foundation model (FM). The company wants to increase the accuracy of the model up to a specific acceptance level. Which solution will meet these requirements?",
        "options": [
            "A. Decrease the batch size.",
            "B. Increase the epochs.",
            "C. Decrease the epochs.",
            "D. Increase the temperature parameter."
        ],
        "answer": "B. Increase the epochs.",
        "keywords": ["foundation model", "accuracy", "epochs"],
        "explanation": "Increasing the number of epochs allows the model to learn more effectively from the training data, improving accuracy."
    },
    {
        "question": "A company has built a chatbot that can respond to natural language questions with images. The company wants to ensure that the chatbot does not return inappropriate or unwanted images. Which solution will meet these requirements?",
        "options": [
            "A. Implement moderation APIs.",
            "B. Retrain the model with a general public dataset.",
            "C. Perform model validation.",
            "D. Automate user feedback integration."
        ],
        "answer": "A. Implement moderation APIs.",
        "keywords": ["chatbot", "image moderation", "inappropriate content"],
        "explanation": "Moderation APIs help identify and filter out inappropriate or unwanted content, ensuring the chatbot returns suitable images."
    },
    {
        "question": "A law firm wants to build an AI application by using large language models (LLMs). The application will read legal documents and extract key points from the documents. Which solution meets these requirements?",
        "options": [
            "A. Build an automatic named entity recognition system.",
            "B. Create a recommendation engine.",
            "C. Develop a summarization chatbot.",
            "D. Develop a multi-language translation system."
        ],
        "answer": "C. Develop a summarization chatbot.",
        "keywords": ["LLM", "legal documents", "summarization"],
        "explanation": "A summarization chatbot can efficiently extract and present key points from legal documents, meeting the law firm's needs."
    },
    {
        "question": "A company wants to classify human genes into 20 categories based on gene characteristics. The company needs an ML algorithm to document how the inner mechanism of the model affects the output. Which ML algorithm meets these requirements?",
        "options": [
            "A. Decision trees",
            "B. Linear regression",
            "C. Logistic regression",
            "D. Neural networks"
        ],
        "answer": "A. Decision trees",
        "keywords": ["gene classification", "ML algorithm", "model interpretability"],
        "explanation": "Decision trees provide a transparent and interpretable model structure, allowing documentation of how inputs influence outputs."
    },
    {
        "question": "A company wants to develop a large language model (LLM) application by using Amazon Bedrock and customer data that is uploaded to Amazon S3. The company's security policy states that each team can access data for only the team's own customers. Which solution will meet these requirements?",
        "options": [
            "A. Create an Amazon Bedrock custom service role for each team that has access to only the team's customer data.",
            "B. Create a custom service role that has Amazon S3 access. Ask teams to specify the customer name on each Amazon Bedrock request.",
            "C. Redact personal data in Amazon S3. Update the S3 bucket policy to allow team access to customer data.",
            "D. Create one Amazon Bedrock role that has full Amazon S3 access. Create IAM roles for each team that have access to only each team's customer folders."
        ],
        "answer": "A. Create an Amazon Bedrock custom service role for each team that has access to only the team's customer data.",
        "keywords": ["Amazon Bedrock", "S3 data access", "team-level security"],
        "explanation": "Custom service roles restrict data access to specific teams, ensuring compliance with the company's security policy."
    },
    {
        "question": "A company wants to use a large language model (LLM) on Amazon Bedrock for sentiment analysis. The company wants to know how much information can fit into one prompt. Which consideration will inform the company's decision?",
        "options": [
            "A. Temperature",
            "B. Context window",
            "C. Batch size",
            "D. Model size"
        ],
        "answer": "B. Context window",
        "keywords": ["LLM", "sentiment analysis", "context window"],
        "explanation": "The context window determines the maximum amount of information the model can process in a single prompt."
    },
    {
        "question": "An AI practitioner has built a deep learning model to classify the types of materials in images. The AI practitioner now wants to measure the model performance. Which metric will help the AI practitioner evaluate the performance of the model?",
        "options": [
            "A. Confusion matrix",
            "B. Correlation matrix",
            "C. R2 score",
            "D. Mean squared error (MSE)"
        ],
        "answer": "A. Confusion matrix",
        "keywords": ["deep learning", "image classification", "model performance"],
        "explanation": "The confusion matrix evaluates classification performance by showing true positives, false positives, true negatives, and false negatives."
    },
    {
        "question": "An AI practitioner is building a model to generate images of humans in various professions. The AI practitioner discovered that the input data is biased and that specific attributes affect the image generation and create bias in the model. Which technique will solve the problem?",
        "options": [
            "A. Data augmentation for imbalanced classes",
            "B. Model monitoring for class distribution",
            "C. Retrieval Augmented Generation (RAG)",
            "D. Watermark detection for images"
        ],
        "answer": "A. Data augmentation for imbalanced classes",
        "keywords": ["image generation", "bias", "imbalanced data"],
        "explanation": "Data augmentation helps balance the dataset by artificially increasing underrepresented classes, reducing bias in image generation."
    },
    {
        "question": "A company is building an ML model to analyze archived data. The company must perform inference on large datasets that are multiple GBs in size. The company does not need to access the model predictions immediately. Which Amazon SageMaker inference option will meet these requirements?",
        "options": [
            "A. Batch transform",
            "B. Real-time inference",
            "C. Serverless inference",
            "D. Asynchronous inference"
        ],
        "answer": "A. Batch transform",
        "keywords": ["archived data", "large datasets", "inference"],
        "explanation": "Batch transform processes large datasets in bulk, making it ideal for scenarios where immediate access to predictions is unnecessary."
    },
    {
        "question": "A company needs to choose a model from Amazon Bedrock to use internally. The company must identify a model that generates responses in a style that the company's employees prefer. What should the company do to meet these requirements?",
        "options": [
            "A. Evaluate the models by using built-in prompt datasets.",
            "B. Evaluate the models by using a human workforce and custom prompt datasets.",
            "C. Use public model leaderboards to identify the model.",
            "D. Use the model InvocationLatency runtime metrics in Amazon CloudWatch when trying models."
        ],
        "answer": "B. Evaluate the models by using a human workforce and custom prompt datasets.",
        "keywords": ["Amazon Bedrock", "model evaluation", "preferred style"],
        "explanation": "Using a human workforce with custom prompts allows for evaluation that aligns with internal preferences and style."
    },
    {
        "question": "A company is using the Generative AI Security Scoping Matrix to assess security responsibilities for its solutions. The company has identified four different solution scopes based on the matrix. Which solution scope gives the company the MOST ownership of security responsibilities?",
        "options": [
            "A. Using a third-party enterprise application that has embedded generative AI features.",
            "B. Building an application by using an existing third-party generative AI foundation model (FM).",
            "C. Refining an existing third-party generative AI foundation model (FM) by fine-tuning the model by using data specific to the business.",
            "D. Building and training a generative AI model from scratch by using specific data that a customer owns."
        ],
        "answer": "D. Building and training a generative AI model from scratch by using specific data that a customer owns.",
        "keywords": ["security responsibilities", "generative AI", "ownership"],
        "explanation": "Building and training a model from scratch gives the company full control and ownership of the model and its security."
    },
    {
        "question": "A company uses Amazon SageMaker for its ML pipeline in a production environment. The company has large input data sizes up to 1 GB and processing times up to 1 hour. The company needs near real-time latency. Which SageMaker inference option meets these requirements?",
        "options": [
            "A. Real-time inference",
            "B. Serverless inference",
            "C. Asynchronous inference",
            "D. Batch transform"
        ],
        "answer": "A. Real-time inference",
        "keywords": ["SageMaker", "real-time latency", "large input data"],
        "explanation": "Real-time inference provides low latency for predictions, even with large input data sizes, meeting near real-time requirements."
    },
    {
        "question": "A company wants to use language models to create an application for inference on edge devices. The inference must have the lowest latency possible. Which solution will meet these requirements?",
        "options": [
            "A. Deploy optimized small language models (SLMs) on edge devices.",
            "B. Deploy optimized large language models (LLMs) on edge devices.",
            "C. Incorporate a centralized small language model (SLM) API for asynchronous communication with edge devices.",
            "D. Incorporate a centralized large language model (LLM) API for asynchronous communication with edge devices."
        ],
        "answer": "A. Deploy optimized small language models (SLMs) on edge devices.",
        "keywords": ["edge devices", "inference", "lowest latency"],
        "explanation": "Optimized small language models are lightweight and run efficiently on edge devices, minimizing latency."
    },
    {
        "question": "A company is building a contact center application and wants to gain insights from customer conversations. The company wants to analyze and extract key information from the audio of the customer calls. Which solution meets these requirements?",
        "options": [
            "A. Build a conversational chatbot by using Amazon Lex.",
            "B. Transcribe call recordings by using Amazon Transcribe.",
            "C. Extract information from call recordings by using Amazon SageMaker Model Monitor.",
            "D. Create classification labels by using Amazon Comprehend."
        ],
        "answer": "B. Transcribe call recordings by using Amazon Transcribe.",
        "keywords": ["contact center", "audio analysis", "customer conversations"],
        "explanation": "Amazon Transcribe converts audio to text, making it possible to analyze and extract insights from customer calls."
    },
    {
        "question": "A company wants to build an ML model by using Amazon SageMaker. The company needs to share and manage variables for model development across multiple teams. Which SageMaker feature meets these requirements?",
        "options": [
            "A. Amazon SageMaker Feature Store",
            "B. Amazon SageMaker Data Wrangler",
            "C. Amazon SageMaker Clarify",
            "D. Amazon SageMaker Model Cards"
        ],
        "answer": "A. Amazon SageMaker Feature Store",
        "keywords": ["SageMaker", "shared variables", "multiple teams"],
        "explanation": "The SageMaker Feature Store enables sharing and managing variables, promoting collaboration across teams."
    },
    {
        "question": "A company is using a pre-trained large language model (LLM) to build a chatbot for product recommendations. The company needs the LLM outputs to be short and written in a specific language. Which solution will align the LLM response quality with the company's expectations?",
        "options": [
            "A. Adjust the prompt.",
            "B. Choose an LLM of a different size.",
            "C. Increase the temperature.",
            "D. Increase the Top K value."
        ],
        "answer": "A. Adjust the prompt.",
        "keywords": ["LLM", "product recommendations", "response quality"],
        "explanation": "Adjusting the prompt ensures the LLM generates concise and contextually appropriate responses in the desired language."
    },
    {
        "question": "A company uses a foundation model (FM) from Amazon Bedrock for an AI search tool. The company wants to fine-tune the model to be more accurate by using the company's data. Which strategy will successfully fine-tune the model?",
        "options": [
            "A. Provide labeled data with the prompt field and the completion field.",
            "B. Prepare the training dataset by creating a .txt file that contains multiple lines in .csv format.",
            "C. Purchase Provisioned Throughput for Amazon Bedrock.",
            "D. Train the model on journals and textbooks."
        ],
        "answer": "A. Provide labeled data with the prompt field and the completion field.",
        "keywords": ["Amazon Bedrock", "fine-tuning", "labeled data"],
        "explanation": "Fine-tuning requires labeled data that maps input prompts to desired completions, enabling the model to adapt to specific tasks."
    },
    {
        "question": "An AI practitioner has a database of animal photos. The AI practitioner wants to automatically identify and categorize the animals in the photos without manual human effort. Which strategy meets these requirements?",
        "options": [
            "A. Object detection",
            "B. Anomaly detection",
            "C. Named entity recognition",
            "D. Inpainting"
        ],
        "answer": "A. Object detection",
        "keywords": ["animal photos", "automatic identification", "object detection"],
        "explanation": "Object detection is a computer vision technique used to identify and locate objects within an image, making it suitable for categorizing animals."
    },
    {
        "question": "A research company implemented a chatbot by using a foundation model (FM) from Amazon Bedrock. The chatbot searches for answers to questions from a large database of research papers. After multiple prompt engineering attempts, the company notices that the FM is performing poorly because of the complex scientific terms in the research papers. How can the company improve the performance of the chatbot?",
        "options": [
            "A. Use few-shot prompting to define how the FM can answer the questions.",
            "B. Use domain adaptation fine-tuning to adapt the FM to complex scientific terms.",
            "C. Change the FM inference parameters.",
            "D. Clean the research paper data to remove complex scientific terms."
        ],
        "answer": "B. Use domain adaptation fine-tuning to adapt the FM to complex scientific terms.",
        "keywords": ["Amazon Bedrock", "chatbot", "domain adaptation", "scientific terms"],
        "explanation": "Domain adaptation fine-tuning allows the FM to learn and adapt to domain-specific vocabulary, improving performance on complex scientific terms."
    },
    {
        "question": "A medical company deployed a disease detection model on Amazon Bedrock. To comply with privacy policies, the company wants to prevent the model from including personal patient information in its responses. The company also wants to receive notification when policy violations occur. Which solution meets these requirements?",
        "options": [
            "A. Use Amazon Macie to scan the model's output for sensitive data and set up alerts for potential violations.",
            "B. Configure AWS CloudTrail to monitor the model's responses and create alerts for any detected personal information.",
            "C. Use Guardrails for Amazon Bedrock to filter content. Set up Amazon CloudWatch alarms for notification of policy violations.",
            "D. Implement Amazon SageMaker Model Monitor to detect data drift and receive alerts when model quality degrades."
        ],
        "answer": "C. Use Guardrails for Amazon Bedrock to filter content. Set up Amazon CloudWatch alarms for notification of policy violations.",
        "keywords": ["Amazon Bedrock", "privacy policies", "Guardrails", "policy violations"],
        "explanation": "Guardrails for Amazon Bedrock help filter content to prevent sensitive information leakage, while CloudWatch alarms notify administrators of violations."
    },
    {
        "question": "An education provider is building a question and answer application that uses a generative AI model to explain complex concepts. The education provider wants to automatically change the style of the model response depending on who is asking the question. The education provider will give the model the age range of the user who has asked the question. Which solution meets these requirements with the LEAST implementation effort?",
        "options": [
            "A. Fine-tune the model by using additional training data that is representative of the various age ranges that the application will support.",
            "B. Add a role description to the prompt context that instructs the model of the age range that the response should target.",
            "C. Use chain-of-thought reasoning to deduce the correct style and complexity for a response suitable for that user.",
            "D. Summarize the response text depending on the age of the user so that younger users receive shorter responses."
        ],
        "answer": "B. Add a role description to the prompt context that instructs the model of the age range that the response should target.",
        "keywords": ["generative AI", "complex concepts", "age range", "prompt context"],
        "explanation": "Adding a role description to the prompt is a simple and effective way to tailor responses without additional training or adjustments."
    },
    {
        "question": "A social media company wants to use a large language model (LLM) for content moderation. The company wants to evaluate the LLM outputs for bias and potential discrimination against specific groups or individuals. Which data source should the company use to evaluate the LLM outputs with the LEAST administrative effort?",
        "options": [
            "A. User-generated content",
            "B. Moderation logs",
            "C. Content moderation guidelines",
            "D. Benchmark datasets"
        ],
        "answer": "D. Benchmark datasets",
        "keywords": ["LLM", "content moderation", "bias", "benchmark datasets"],
        "explanation": "Benchmark datasets are pre-defined and widely used for evaluating models, minimizing administrative effort."
    },
    {
        "question": "Which strategy evaluates the accuracy of a foundation model (FM) that is used in image classification tasks?",
        "options": [
            "A. Calculate the total cost of resources used by the model.",
            "B. Measure the model's accuracy against a predefined benchmark dataset.",
            "C. Count the number of layers in the neural network.",
            "D. Assess the color accuracy of images processed by the model."
        ],
        "answer": "B. Measure the model's accuracy against a predefined benchmark dataset.",
        "keywords": ["foundation model", "image classification", "accuracy evaluation"],
        "explanation": "Measuring accuracy against a benchmark dataset is the standard method for evaluating image classification models."
    },
    {
        "question": "A company has terabytes of data in a database that the company can use for business analysis. The company wants to build an AI-based application that can build a SQL query from input text that employees provide. The employees have minimal experience with technology. Which solution meets these requirements?",
        "options": [
            "A. Generative pre-trained transformers (GPT)",
            "B. Residual neural network",
            "C. Support vector machine",
            "D. WaveNet"
        ],
        "answer": "A. Generative pre-trained transformers (GPT)",
        "keywords": ["SQL query", "minimal experience", "generative AI"],
        "explanation": "GPT models can understand natural language inputs and generate SQL queries, making them suitable for this task."
    },
    {
        "question": "Which metric measures the runtime efficiency of operating AI models?",
        "options": [
            "A. Customer satisfaction score (CSAT)",
            "B. Training time for each epoch",
            "C. Average response time",
            "D. Number of training instances"
        ],
        "answer": "C. Average response time",
        "keywords": ["runtime efficiency", "AI models", "response time"],
        "explanation": "Average response time directly reflects the runtime efficiency of an AI model during inference."
    },
    {
        "question": "Which option is a benefit of ongoing pre-training when fine-tuning a foundation model (FM)?",
        "options": [
            "A. Helps decrease the model's complexity",
            "B. Improves model performance over time",
            "C. Decreases the training time requirement",
            "D. Optimizes model inference time"
        ],
        "answer": "B. Improves model performance over time",
        "keywords": ["ongoing pre-training", "fine-tuning", "performance improvement"],
        "explanation": "Ongoing pre-training enhances the model's understanding, leading to better performance in specific tasks over time."
    },
    {
        "question": "An AI practitioner wants to use a foundation model (FM) to design a search application. The search application must handle queries that have text and images. Which type of FM should the AI practitioner use to power the search application?",
        "options": [
            "A. Multi-modal embedding model",
            "B. Text embedding model",
            "C. Multi-modal generation model",
            "D. Image generation model"
        ],
        "answer": "A. Multi-modal embedding model",
        "keywords": ["search application", "text and images", "multi-modal"],
        "explanation": "Multi-modal embedding models are designed to handle both text and images, making them suitable for search applications."
    },
    {
        "question": "A company is using an Amazon Bedrock base model to summarize documents for an internal use case. The company trained a custom model to improve the summarization quality. Which action must the company take to use the custom model through Amazon Bedrock?",
        "options": [
            "A. Purchase Provisioned Throughput for the custom model.",
            "B. Deploy the custom model in an Amazon SageMaker endpoint for real-time inference.",
            "C. Register the model with the Amazon SageMaker Model Registry.",
            "D. Grant access to the custom model in Amazon Bedrock."
        ],
        "answer": "B. Deploy the custom model in an Amazon SageMaker endpoint for real-time inference.",
        "keywords": ["Amazon Bedrock", "custom model", "summarization"],
        "explanation": "Deploying the custom model on a SageMaker endpoint enables real-time inference through Amazon Bedrock."
    },
    {
        "question": "A company has built a solution by using generative AI. The solution uses large language models (LLMs) to translate training manuals from English into other languages. The company wants to evaluate the accuracy of the solution by examining the text generated for the manuals. Which model evaluation strategy meets these requirements?",
        "options": [
            "A. Bilingual Evaluation Understudy (BLEU)",
            "B. Root mean squared error (RMSE)",
            "C. Recall-Oriented Understudy for Gisting Evaluation (ROUGE)",
            "D. F1 score"
        ],
        "answer": "A. Bilingual Evaluation Understudy (BLEU)",
        "keywords": ["generative AI", "translation", "accuracy evaluation"],
        "explanation": "The BLEU metric is widely used for evaluating the quality of machine-translated text by comparing it to reference translations."
    },
    {
        "question": "How can companies use large language models (LLMs) securely on Amazon Bedrock?",
        "options": [
            "A. Design clear and specific prompts. Configure AWS Identity and Access Management (IAM) roles and policies by using least privilege access.",
            "B. Enable AWS Audit Manager for automatic model evaluation jobs.",
            "C. Enable Amazon Bedrock automatic model evaluation jobs.",
            "D. Use Amazon CloudWatch Logs to make models explainable and to monitor for bias."
        ],
        "answer": "A. Design clear and specific prompts. Configure AWS Identity and Access Management (IAM) roles and policies by using least privilege access.",
        "keywords": ["LLM security", "Amazon Bedrock", "IAM policies"],
        "explanation": "Using specific prompts and IAM policies with least privilege access minimizes security risks when deploying LLMs on Bedrock."
    },
    {
        "question": "A company is building a customer service chatbot. The company wants the chatbot to improve its responses by learning from past interactions and online resources. Which AI learning strategy provides this self-improvement capability?",
        "options": [
            "A. Supervised learning with a manually curated dataset of good responses and bad responses",
            "B. Reinforcement learning with rewards for positive customer feedback",
            "C. Unsupervised learning to find clusters of similar customer inquiries",
            "D. Supervised learning with a continuously updated FAQ database"
        ],
        "answer": "B. Reinforcement learning with rewards for positive customer feedback",
        "keywords": ["customer service chatbot", "self-improvement", "reinforcement learning"],
        "explanation": "Reinforcement learning uses a reward mechanism, such as positive customer feedback, to improve the chatbot's responses over time."
    },
    {
        "question": "A company wants to deploy a conversational chatbot to answer customer questions. The chatbot is based on a fine-tuned Amazon SageMaker JumpStart model. The application must comply with multiple regulatory frameworks. Which capabilities can the company show compliance for? (Select TWO.)",
        "options": [
            "A. Auto scaling inference endpoints",
            "B. Threat detection",
            "C. Data protection",
            "D. Cost optimization",
            "E. Loosely coupled microservices"
        ],
        "answer": ["B. Threat detection", "C. Data protection"],
        "keywords": ["SageMaker JumpStart", "compliance", "data protection", "threat detection"],
        "explanation": "Threat detection and data protection are essential for meeting regulatory frameworks, ensuring the chatbot's compliance with security standards."
    },
    {
        "question": "An e-commerce company wants to build a solution to determine customer sentiments based on written customer reviews of products. Which AWS services meet these requirements? (Select TWO.)",
        "options": [
            "A. Amazon Lex",
            "B. Amazon Comprehend",
            "C. Amazon Polly",
            "D. Amazon Bedrock",
            "E. Amazon Rekognition"
        ],
        "answer": ["B. Amazon Comprehend", "D. Amazon Bedrock"],
        "keywords": ["sentiment analysis", "customer reviews", "Comprehend", "Bedrock"],
        "explanation": "Amazon Comprehend specializes in sentiment analysis, while Amazon Bedrock provides foundation models for advanced text processing."
    },
    {
        "question": "A company wants to use a pre-trained generative AI model to generate content for its marketing campaigns. The company needs to ensure that the generated content aligns with the company's brand voice and messaging requirements. Which solution meets these requirements?",
        "options": [
            "A. Optimize the model's architecture and hyperparameters to improve the model's overall performance.",
            "B. Increase the model's complexity by adding more layers to the model's architecture.",
            "C. Create effective prompts that provide clear instructions and context to guide the model's generation.",
            "D. Select a large, diverse dataset to pre-train a new generative model."
        ],
        "answer": "C. Create effective prompts that provide clear instructions and context to guide the model's generation.",
        "keywords": ["generative AI", "marketing campaigns", "brand voice", "prompts"],
        "explanation": "Effective prompts guide the AI model to produce content that aligns with specific requirements, such as tone and messaging."
    },
    {
        "question": "A student at a university is copying content from generative AI to write essays. Which challenge of responsible generative AI does this scenario represent?",
        "options": [
            "A. Toxicity",
            "B. Hallucinations",
            "C. Plagiarism",
            "D. Privacy"
        ],
        "answer": "C. Plagiarism",
        "keywords": ["generative AI", "essay writing", "responsible AI"],
        "explanation": "Plagiarism refers to copying content without proper attribution, which is a significant ethical concern in AI usage."
    },
    {
        "question": "A company wants to make a chatbot to help customers. The chatbot will help solve technical problems without human intervention. The company chose a foundation model (FM) for the chatbot. The chatbot needs to produce responses that adhere to company tone. Which solution meets these requirements?",
        "options": [
            "A. Set a low limit on the number of tokens the FM can produce.",
            "B. Use batch inferencing to process detailed responses.",
            "C. Experiment and refine the prompt until the FM produces the desired responses.",
            "D. Define a higher number for the temperature parameter."
        ],
        "answer": "C. Experiment and refine the prompt until the FM produces the desired responses.",
        "keywords": ["chatbot", "foundation model", "technical problems"],
        "explanation": "Refining the prompt allows the FM to align its responses with the desired company tone and problem-solving style."
    },
    {
        "question": "A company has installed a security camera. The company uses an ML model to evaluate the security camera footage for potential thefts. The company has discovered that the model disproportionately flags people who are members of a specific ethnic group. Which type of bias is affecting the model output?",
        "options": [
            "A. Measurement bias",
            "B. Sampling bias",
            "C. Observer bias",
            "D. Confirmation bias"
        ],
        "answer": "B. Sampling bias",
        "keywords": ["ML model", "security footage", "bias"],
        "explanation": "Sampling bias occurs when the training data is not representative, leading to skewed predictions for certain groups."
    },
    {
        "question": "A company wants to use a large language model (LLM) on Amazon Bedrock for sentiment analysis. The company wants to classify the sentiment of text passages as positive or negative. Which prompt engineering strategy meets these requirements?",
        "options": [
            "A. Provide examples of text passages with corresponding positive or negative labels in the prompt followed by the new text passage to be classified.",
            "B. Provide a detailed explanation of sentiment analysis and how LLMs work in the prompt.",
            "C. Provide the new text passage to be classified without any additional context or examples.",
            "D. Provide the new text passage with a few examples of unrelated tasks, such as text summarization or question answering."
        ],
        "answer": "A. Provide examples of text passages with corresponding positive or negative labels in the prompt followed by the new text passage to be classified.",
        "keywords": ["sentiment analysis", "prompt engineering", "LLM"],
        "explanation": "Providing labeled examples in the prompt helps the LLM understand the task and improves classification accuracy."
    },
    {
        "question": "Which AWS service or feature can help an AI development team quickly deploy and consume a foundation model (FM) within the team's VPC?",
        "options": [
            "A. Amazon Personalize",
            "B. Amazon SageMaker JumpStart",
            "C. PartyRock, an Amazon Bedrock Playground",
            "D. Amazon SageMaker endpoints"
        ],
        "answer": "D. Amazon SageMaker endpoints",
        "keywords": ["foundation model", "VPC", "deployment"],
        "explanation": "SageMaker endpoints enable easy and secure deployment of foundation models within a VPC environment."
    },
    {
        "question": "A company has a database of petabytes of unstructured data from internal sources. The company wants to transform this data into a structured format so that its data scientists can perform machine learning (ML) tasks. Which service will meet these requirements?",
        "options": [
            "A. Amazon Lex",
            "B. Amazon Rekognition",
            "C. Amazon Kinesis Data Streams",
            "D. AWS Glue"
        ],
        "answer": "D. AWS Glue",
        "keywords": ["unstructured data", "structured format", "AWS Glue"],
        "explanation": "AWS Glue extracts and transforms unstructured data into a structured format, making it usable for ML tasks."
    },
    {
        "question": "A company has thousands of customer support interactions per day and wants to analyze these interactions to identify frequently asked questions and develop insights. Which AWS service can the company use to meet this requirement?",
        "options": [
            "A. Amazon Lex",
            "B. Amazon Comprehend",
            "C. Amazon Transcribe",
            "D. Amazon Translate"
        ],
        "answer": "B. Amazon Comprehend",
        "keywords": ["customer support", "text analysis", "frequently asked questions"],
        "explanation": "Amazon Comprehend performs natural language processing to extract insights and trends from large volumes of text."
    }
]
