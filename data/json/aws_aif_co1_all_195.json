[
    {
        "question": "An AI practitioner trained a custom model on Amazon Bedrock by using a training dataset that contains confidential data. The AI practitioner wants to ensure that the custom model does not generate inference responses based on confidential data. How should the AI practitioner prevent responses based on confidential data?",
        "options": [
            "A. Delete the custom model. Remove the confidential data from the training dataset. Retrain the custom model.",
            "B. Mask the confidential data in the inference responses by using dynamic data masking.",
            "C. Encrypt the confidential data in the inference responses by using Amazon SageMaker.",
            "D. Encrypt the confidential data in the custom model by using AWS Key Management Service (AWS KMS)."
        ],
        "answer": "A. Delete the custom model. Remove the confidential data from the training dataset. Retrain the custom model.",
        "keywords": ["Amazon Bedrock", "confidential data", "prevent responses"],
        "explanation": "Deleting the custom model and retraining it without confidential data ensures no sensitive information is included in inference outputs."
    },
    {
        "question": "Which feature of Amazon OpenSearch Service gives companies the ability to build vector database applications?",
        "options": [
            "A. Integration with Amazon S3 for object storage",
            "B. Support for geospatial indexing and queries",
            "C. Scalable index management and nearest neighbor search capability",
            "D. Ability to perform real-time analysis on streaming data"
        ],
        "answer": "C. Scalable index management and nearest neighbor search capability",
        "keywords": ["Amazon OpenSearch", "vector database", "nearest neighbor search"],
        "explanation": "This feature enables efficient storage and retrieval for vector database applications, crucial for search and recommendation systems."
    },
    {
        "question": "A company wants to display the total sales for its top-selling products across various retail locations in the past 12 months. Which AWS solution should the company use to automate the generation of graphs?",
        "options": [
            "A. Amazon Q in Amazon EC2",
            "B. Amazon Q Developer",
            "C. Amazon Q in Amazon QuickSight",
            "D. Amazon Q in AWS Chatbot"
        ],
        "answer": "C. Amazon Q in Amazon QuickSight",
        "keywords": ["total sales", "top-selling products", "graphs"],
        "explanation": "Amazon QuickSight automates data visualization, making it the optimal choice for generating graphs for sales data."
    },
    {
        "question": "A company wants to build an interactive application for children that generates new stories based on classic stories. The company wants to use Amazon Bedrock and needs to ensure that the results and topics are appropriate for children. Which AWS service or feature will meet these requirements?",
        "options": [
            "A. Amazon Rekognition",
            "B. Amazon Bedrock playgrounds",
            "C. Guardrails for Amazon Bedrock",
            "D. Agents for Amazon Bedrock"
        ],
        "answer": "C. Guardrails for Amazon Bedrock",
        "keywords": ["interactive application", "children", "appropriate topics"],
        "explanation": "Guardrails ensure the generated content aligns with desired standards, especially for sensitive audiences like children."
    },
    {
        "question": "A company has developed an ML model for image classification. The company wants to deploy the model to production so that a web application can use the model. The company needs to implement a solution to host the model and serve predictions without managing any of the underlying infrastructure. Which solution will meet these requirements?",
        "options": [
            "A. Use Amazon SageMaker Serverless Inference to deploy the model.",
            "B. Use Amazon CloudFront to deploy the model.",
            "C. Use Amazon API Gateway to host the model and serve predictions.",
            "D. Use AWS Batch to host the model and serve predictions."
        ],
        "answer": "A. Use Amazon SageMaker Serverless Inference to deploy the model.",
        "keywords": ["ML model", "image classification", "host predictions"],
        "explanation": "Serverless Inference in SageMaker allows deployment without managing servers, ideal for production ML workloads."
    },
    {
        "question": "A company has petabytes of unlabeled customer data to use for an advertisement campaign. The company wants to classify its customers into tiers to advertise and promote the company's products. Which methodology should the company use to meet these requirements?",
        "options": [
            "A. Supervised learning",
            "B. Unsupervised learning",
            "C. Reinforcement learning",
            "D. Reinforcement learning from human feedback (RLHF)"
        ],
        "answer": "B. Unsupervised learning",
        "keywords": ["unlabeled data", "classify customers", "advertisement campaign"],
        "explanation": "Unsupervised learning identifies patterns in unlabeled data, making it suitable for tier classification."
    },
    {
        "question": "A company makes forecasts each quarter to decide how to optimize operations to meet expected demand. The company uses ML models to make these forecasts. An AI practitioner is writing a report about the trained ML models to provide transparency and explainability to company stakeholders. What should the AI practitioner include in the report to meet the transparency and explainability requirements?",
        "options": [
            "A. Code for model training",
            "B. Partial dependence plots (PDPs)",
            "C. Sample data for training",
            "D. Model convergence tables"
        ],
        "answer": "B. Partial dependence plots (PDPs)",
        "keywords": ["transparency", "explainability", "ML forecasts"],
        "explanation": "Partial dependence plots visually explain the influence of input features on predictions, enhancing stakeholder understanding."
    },
    {
        "question": "Which option is a use case for generative AI models?",
        "options": [
            "A. Improving network security by using intrusion detection systems",
            "B. Creating photorealistic images from text descriptions for digital marketing",
            "C. Enhancing database performance by using optimized indexing",
            "D. Analyzing financial data to forecast stock market trends"
        ],
        "answer": "B. Creating photorealistic images from text descriptions for digital marketing",
        "keywords": ["generative AI", "photorealistic images", "marketing"],
        "explanation": "Generative AI models excel at creating realistic content like images, aiding digital marketing efforts."
    },
    {
        "question": "An AI practitioner is using a large language model (LLM) to create content for marketing campaigns. The generated content sounds plausible and factual but is incorrect. Which problem is the LLM having?",
        "options": [
            "A. Data leakage",
            "B. Hallucination",
            "C. Overfitting",
            "D. Underfitting"
        ],
        "answer": "B. Hallucination",
        "keywords": ["LLM", "plausible content", "incorrect"],
        "explanation": "Hallucination refers to AI generating confident but incorrect information, common in LLM outputs."
    },
    {
        "question": "A loan company is building a generative AI-based solution to offer new applicants discounts based on specific business criteria. The company wants to build and use an AI model responsibly to minimize bias that could negatively affect some customers. Which actions should the company take to meet these requirements? (Select TWO.)",
        "options": [
            "A. Detect imbalances or disparities in the data.",
            "B. Ensure that the model runs frequently.",
            "C. Evaluate the model's behavior so that the company can provide transparency to stakeholders.",
            "D. Use the Recall-Oriented Understudy for Gisting Evaluation (ROUGE) technique to ensure that the model is 100% accurate.",
            "E. Ensure that the model's inference time is within the accepted limits."
        ],
        "answer": [
            "A. Detect imbalances or disparities in the data.",
            "C. Evaluate the model's behavior so that the company can provide transparency to stakeholders."
        ],
        "keywords": ["generative AI", "bias", "responsible AI"],
        "explanation": "Detecting data imbalances and evaluating model behavior are critical for building responsible AI solutions."
    },
    {
        "question": "A medical company is customizing a foundation model (FM) for diagnostic purposes. The company needs the model to be transparent and explainable to meet regulatory requirements. Which solution will meet these requirements?",
        "options": [
            "A. Configure the security and compliance by using Amazon Inspector.",
            "B. Generate simple metrics, reports, and examples by using Amazon SageMaker Clarify.",
            "C. Encrypt and secure training data by using Amazon Macie.",
            "D. Gather more data. Use Amazon Rekognition to add custom labels to the data."
        ],
        "answer": "B. Generate simple metrics, reports, and examples by using Amazon SageMaker Clarify.",
        "keywords": ["diagnostic purposes", "transparent", "explainable", "SageMaker Clarify"],
        "explanation": "Amazon SageMaker Clarify generates metrics and examples to ensure transparency and explainability, which are crucial for regulatory compliance."
    },
    {
        "question": "A company is building a solution to generate images for protective eyewear. The solution must have high accuracy and must minimize the risk of incorrect annotations. Which solution will meet these requirements?",
        "options": [
            "A. Human-in-the-loop validation by using Amazon SageMaker Ground Truth Plus",
            "B. Data augmentation by using an Amazon Bedrock knowledge base",
            "C. Image recognition by using Amazon Rekognition",
            "D. Data summarization by using Amazon QuickSight"
        ],
        "answer": "A. Human-in-the-loop validation by using Amazon SageMaker Ground Truth Plus",
        "keywords": ["protective eyewear", "high accuracy", "incorrect annotations"],
        "explanation": "Human-in-the-loop validation ensures the quality of annotations, reducing risks in the image generation process."
    },
    {
        "question": "A security company is using Amazon Bedrock to run foundation models (FMs). The company wants to ensure that only authorized users invoke the models. The company needs to identify any unauthorized access attempts to set appropriate AWS Identity and Access Management (IAM) policies and roles for future iterations of the FMs. Which AWS service should the company use to identify unauthorized users that are trying to access Amazon Bedrock?",
        "options": [
            "A. AWS Audit Manager",
            "B. AWS CloudTrail",
            "C. Amazon Fraud Detector",
            "D. AWS Trusted Advisor"
        ],
        "answer": "B. AWS CloudTrail",
        "keywords": ["Amazon Bedrock", "unauthorized users", "IAM policies", "AWS CloudTrail"],
        "explanation": "AWS CloudTrail logs API activity, enabling the company to monitor and identify unauthorized access attempts."
    },
    {
        "question": "A company manually reviews all submitted resumes in PDF format. As the company grows, the company expects the volume of resumes to exceed the company's review capacity. The company needs an automated system to convert the PDF resumes into plain text format for additional processing. Which AWS service meets this requirement?",
        "options": [
            "A. Amazon Textract",
            "B. Amazon Personalize",
            "C. Amazon Lex",
            "D. Amazon Transcribe"
        ],
        "answer": "A. Amazon Textract",
        "keywords": ["PDF resumes", "plain text", "automated system"],
        "explanation": "Amazon Textract extracts text from documents, making it ideal for automating resume processing."
    },
    {
        "question": "A company wants to use large language models (LLMs) with Amazon Bedrock to develop a chat interface for the company's product manuals. The manuals are stored as PDF files. Which solution meets these requirements MOST cost-effectively?",
        "options": [
            "A. Use prompt engineering to add one PDF file as context to the user prompt when the prompt is submitted to Amazon Bedrock.",
            "B. Use prompt engineering to add all the PDF files as context to the user prompt when the prompt is submitted to Amazon Bedrock.",
            "C. Use all the PDF documents to fine-tune a model with Amazon Bedrock. Use the fine-tuned model to process user prompts.",
            "D. Upload PDF documents to an Amazon Bedrock knowledge base. Use the knowledge base to provide context when users submit prompts to Amazon Bedrock."
        ],
        "answer": "D. Upload PDF documents to an Amazon Bedrock knowledge base. Use the knowledge base to provide context when users submit prompts to Amazon Bedrock.",
        "keywords": ["Amazon Bedrock", "PDF files", "knowledge base", "cost-effective"],
        "explanation": "Using a knowledge base in Amazon Bedrock is more cost-effective than fine-tuning or processing all files in real-time."
    },
    {
        "question": "Which term describes the numerical representations of real-world objects and concepts that AI and natural language processing (NLP) models use to improve understanding of textual information?",
        "options": [
            "A. Embeddings",
            "B. Tokens",
            "C. Models",
            "D. Binaries"
        ],
        "answer": "A. Embeddings",
        "keywords": ["numerical representations", "AI", "NLP", "textual information"],
        "explanation": "Embeddings are mathematical representations that improve AI models' ability to understand and process text."
    },
    {
        "question": "A company is building an application that needs to generate synthetic data that is based on existing data. Which type of model can the company use to meet this requirement?",
        "options": [
            "A. Generative adversarial network (GAN)",
            "B. XGBoost",
            "C. Residual neural network",
            "D. WaveNet"
        ],
        "answer": "A. Generative adversarial network (GAN)",
        "keywords": ["synthetic data", "existing data", "GAN"],
        "explanation": "Generative adversarial networks are widely used for generating synthetic data by training two neural networks in competition."
    },
    {
        "question": "A company wants to use generative AI to increase developer productivity and software development. The company wants to use Amazon Q Developer. What can Amazon Q Developer do to help the company meet these requirements?",
        "options": [
            "A. Create software snippets, reference tracking, and open-source license tracking.",
            "B. Run an application without provisioning or managing servers.",
            "C. Enable voice commands for coding and providing natural language search.",
            "D. Convert audio files to text documents by using ML models."
        ],
        "answer": "C. Enable voice commands for coding and providing natural language search.",
        "keywords": ["generative AI", "developer productivity", "Amazon Q Developer"],
        "explanation": "Amazon Q Developer uses generative AI to enable natural language interactions, improving developer efficiency."
    },
    {
        "question": "A company wants to create an application by using Amazon Bedrock. The company has a limited budget and prefers flexibility without long-term commitment. Which Amazon Bedrock pricing model meets these requirements?",
        "options": [
            "A. On-Demand",
            "B. Model customization",
            "C. Provisioned Throughput",
            "D. Spot Instance"
        ],
        "answer": "A. On-Demand",
        "keywords": ["Amazon Bedrock", "pricing model", "flexibility", "limited budget"],
        "explanation": "On-Demand pricing provides flexibility without requiring long-term commitments, making it ideal for budget-conscious applications."
    },
    {
        "question": "A digital devices company wants to predict customer demand for memory hardware. The company does not have coding experience or knowledge of ML algorithms and needs to develop a data-driven predictive model. The company needs to perform analysis on internal data and external data. Which solution will meet these requirements?",
        "options": [
            "A. Store the data in Amazon S3. Create ML models and demand forecast predictions by using Amazon SageMaker built-in algorithms that use the data from Amazon S3.",
            "B. Import the data into Amazon SageMaker Data Wrangler. Create ML models and demand forecast predictions by using SageMaker built-in algorithms.",
            "C. Import the data into Amazon SageMaker Data Wrangler. Build ML models and demand forecast predictions by using an Amazon Personalize Trending-Now recipe.",
            "D. Import the data into Amazon SageMaker Canvas. Build ML models and demand forecast predictions by selecting the values in the data from SageMaker Canvas."
        ],
        "answer": "D. Import the data into Amazon SageMaker Canvas. Build ML models and demand forecast predictions by selecting the values in the data from SageMaker Canvas.",
        "keywords": ["predictive model", "customer demand", "SageMaker Canvas"],
        "explanation": "SageMaker Canvas allows non-technical users to build predictive models without requiring coding skills, leveraging internal and external data."
    },
    {
        "question": "What are tokens in the context of generative AI models?",
        "options": [
            "A. Tokens are the basic units of input and output that a generative AI model operates on, representing words, subwords, or other linguistic units.",
            "B. Tokens are the mathematical representations of words or concepts used in generative AI models.",
            "C. Tokens are the pre-trained weights of a generative AI model that are fine-tuned for specific tasks.",
            "D. Tokens are the specific prompts or instructions given to a generative AI model to generate output."
        ],
        "answer": "A. Tokens are the basic units of input and output that a generative AI model operates on, representing words, subwords, or other linguistic units.",
        "keywords": ["generative AI", "tokens", "linguistic units"],
        "explanation": "Tokens represent the smallest units of text that a generative AI model processes, such as words or subwords."
    },
    {
        "question": "An AI practitioner is using an Amazon Bedrock base model to summarize session chats from the customer service department. The AI practitioner wants to store invocation logs to monitor model input and output data. Which strategy should the AI practitioner use?",
        "options": [
            "A. Configure AWS CloudTrail as the logs destination for the model.",
            "B. Enable invocation logging in Amazon Bedrock.",
            "C. Configure AWS Audit Manager as the logs destination for the model.",
            "D. Configure model invocation logging in Amazon EventBridge."
        ],
        "answer": "B. Enable invocation logging in Amazon Bedrock.",
        "keywords": ["Amazon Bedrock", "invocation logs", "monitor input and output"],
        "explanation": "Amazon Bedrock supports invocation logging directly, allowing users to track input and output data for monitoring and compliance."
    },
    {
        "question": "A company needs to build its own large language model (LLM) based on only the company's private data. The company is concerned about the environmental effect of the training process. Which Amazon EC2 instance type has the LEAST environmental effect when training LLMs?",
        "options": [
            "A. Amazon EC2 C series",
            "B. Amazon EC2 G series",
            "C. Amazon EC2 P series",
            "D. Amazon EC2 Trn series"
        ],
        "answer": "D. Amazon EC2 Trn series",
        "keywords": ["LLM training", "EC2 instances", "environmental impact"],
        "explanation": "The Amazon EC2 Trn series instances are designed for efficient ML model training and have the lowest environmental impact."
    },
    {
        "question": "A financial institution is using Amazon Bedrock to develop an AI application. The application is hosted in a VPC. To meet regulatory compliance standards, the VPC is not allowed access to any internet traffic. Which AWS service or feature will meet these requirements?",
        "options": [
            "A. AWS PrivateLink",
            "B. Amazon Macie",
            "C. Amazon CloudFront",
            "D. Internet gateway"
        ],
        "answer": "A. AWS PrivateLink",
        "keywords": ["Amazon Bedrock", "VPC", "regulatory compliance", "internet traffic"],
        "explanation": "AWS PrivateLink allows secure access to services without internet connectivity, meeting compliance requirements."
    },
    {
        "question": "A company built a deep learning model for object detection and deployed the model to production. Which AI process occurs when the model analyzes a new image to identify objects?",
        "options": [
            "A. Training",
            "B. Inference",
            "C. Model deployment",
            "D. Bias correction"
        ],
        "answer": "B. Inference",
        "keywords": ["deep learning", "object detection", "inference"],
        "explanation": "Inference refers to the process of analyzing new data using a trained model to make predictions or identify patterns."
    },
    {
        "question": "A company is using Amazon SageMaker Studio notebooks to build and train ML models. The company stores the data in an Amazon S3 bucket. The company needs to manage the flow of data from Amazon S3 to SageMaker Studio notebooks. Which solution will meet this requirement?",
        "options": [
            "A. Use Amazon Inspector to monitor SageMaker Studio.",
            "B. Use Amazon Macie to monitor SageMaker Studio.",
            "C. Configure SageMaker to use a VPC with an S3 endpoint.",
            "D. Configure SageMaker to use S3 Glacier Deep Archive."
        ],
        "answer": "C. Configure SageMaker to use a VPC with an S3 endpoint.",
        "keywords": ["SageMaker Studio", "S3 endpoint", "data flow management"],
        "explanation": "Using a VPC with an S3 endpoint ensures secure and efficient data flow between Amazon S3 and SageMaker Studio."
    },
    {
        "question": "A company is using domain-specific models. The company wants to avoid creating new models from the beginning. The company instead wants to adapt pre-trained models to create models for new, related tasks. Which ML strategy meets these requirements?",
        "options": [
            "A. Increase the number of epochs.",
            "B. Use transfer learning.",
            "C. Decrease the number of epochs.",
            "D. Use unsupervised learning."
        ],
        "answer": "B. Use transfer learning.",
        "keywords": ["domain-specific models", "pre-trained models", "transfer learning"],
        "explanation": "Transfer learning allows leveraging pre-trained models to adapt them for new, related tasks, saving time and resources."
    },
    {
        "question": "A company wants to use AI to protect its application from threats. The AI solution needs to check if an IP address is from a suspicious source. Which solution meets these requirements?",
        "options": [
            "A. Build a speech recognition system.",
            "B. Create a natural language processing (NLP) named entity recognition system.",
            "C. Develop an anomaly detection system.",
            "D. Create a fraud forecasting system."
        ],
        "answer": "C. Develop an anomaly detection system.",
        "keywords": ["AI security", "IP address threats", "anomaly detection"],
        "explanation": "Anomaly detection systems identify patterns in data that deviate from expected behavior, ideal for detecting suspicious IP addresses."
    },
    {
        "question": "A company wants to use a large language model (LLM) to develop a conversational agent. The company needs to prevent the LLM from being manipulated with common prompt engineering techniques to perform undesirable actions or expose sensitive information. Which action will reduce these risks?",
        "options": [
            "A. Create a prompt template that teaches the LLM to detect attack patterns.",
            "B. Increase the temperature parameter on invocation requests to the LLM.",
            "C. Avoid using LLMs that are not listed in Amazon SageMaker.",
            "D. Decrease the number of input tokens on invocations of the LLM."
        ],
        "answer": "A. Create a prompt template that teaches the LLM to detect attack patterns.",
        "keywords": ["LLM", "security", "prompt engineering"],
        "explanation": "Prompt templates designed to detect attack patterns reduce the risk of manipulation and enhance security."
    },
    {
        "question": "A company is developing a new model to predict the prices of specific items. The model performed well on the training dataset. When the company deployed the model to production, the model's performance decreased significantly. What should the company do to mitigate this problem?",
        "options": [
            "A. Reduce the volume of data that is used in training.",
            "B. Add hyperparameters to the model.",
            "C. Increase the volume of data that is used in training.",
            "D. Increase the model training time."
        ],
        "answer": "C. Increase the volume of data that is used in training.",
        "keywords": ["model performance", "training data", "production environment"],
        "explanation": "Increasing the training data volume improves the model's ability to generalize, reducing performance degradation in production."
    },
    {
        "question": "A company wants to create a chatbot by using a foundation model (FM) on Amazon Bedrock. The FM needs to access encrypted data that is stored in an Amazon S3 bucket. The data is encrypted with Amazon S3 managed keys (SSE-S3). The FM encounters a failure when attempting to access the S3 bucket data. Which solution will meet these requirements?",
        "options": [
            "A. Ensure that the role that Amazon Bedrock assumes has permission to decrypt data with the correct encryption key.",
            "B. Set the access permissions for the S3 buckets to allow public access to enable access over the internet.",
            "C. Use prompt engineering techniques to tell the model to look for information in Amazon S3.",
            "D. Ensure that the S3 data does not contain sensitive information."
        ],
        "answer": "A. Ensure that the role that Amazon Bedrock assumes has permission to decrypt data with the correct encryption key.",
        "keywords": ["Amazon Bedrock", "S3 encryption", "SSE-S3"],
        "explanation": "To access encrypted data, the role assumed by Amazon Bedrock must have the necessary permissions to decrypt the data using the correct encryption key."
    },
    {
        "question": "A company has a foundation model (FM) that was customized by using Amazon Bedrock to answer customer queries about products. The company wants to validate the model's responses to new types of queries. The company needs to upload a new dataset that Amazon Bedrock can use for validation. Which AWS service meets these requirements?",
        "options": [
            "A. Amazon S3",
            "B. Amazon Elastic Block Store (Amazon EBS)",
            "C. Amazon Elastic File System (Amazon EFS)",
            "D. AWS Snowcone"
        ],
        "answer": "A. Amazon S3",
        "keywords": ["Amazon Bedrock", "validation", "dataset upload"],
        "explanation": "Amazon S3 is used for storing datasets and making them accessible for validation or training purposes."
    },
    {
        "question": "A company wants to assess the costs that are associated with using a large language model (LLM) to generate inferences. The company wants to use Amazon Bedrock to build generative AI applications. Which factor will drive the inference costs?",
        "options": [
            "A. Number of tokens consumed",
            "B. Temperature value",
            "C. Amount of data used to train the LLM",
            "D. Total training time"
        ],
        "answer": "A. Number of tokens consumed",
        "keywords": ["LLM", "Amazon Bedrock", "inference costs"],
        "explanation": "Inference costs are primarily driven by the number of tokens consumed during the input and output processing of the model."
    },
    {
        "question": "An AI company periodically evaluates its systems and processes with the help of independent software vendors (ISVs). The company needs to receive email message notifications when an ISV's compliance reports become available. Which AWS service can the company use to meet this requirement?",
        "options": [
            "A. AWS Audit Manager",
            "B. AWS Artifact",
            "C. AWS Trusted Advisor",
            "D. AWS Data Exchange"
        ],
        "answer": "B. AWS Artifact",
        "keywords": ["compliance", "ISV reports", "notifications"],
        "explanation": "AWS Artifact provides access to compliance-related reports and can notify users when new reports are available."
    },
    {
        "question": "A company wants to use a large language model (LLM) on Amazon Bedrock for sentiment analysis. The company needs the LLM to produce more consistent responses to the same input prompt. Which adjustment to an inference parameter should the company make to meet these requirements?",
        "options": [
            "A. Decrease the temperature value",
            "B. Increase the temperature value",
            "C. Decrease the length of output tokens",
            "D. Increase the maximum generation length"
        ],
        "answer": "A. Decrease the temperature value",
        "keywords": ["LLM", "sentiment analysis", "temperature"],
        "explanation": "Decreasing the temperature value makes the model produce more deterministic and consistent responses."
    },
    {
        "question": "A company is implementing the Amazon Titan foundation model (FM) by using Amazon Bedrock. The company needs to supplement the model by using relevant data from the company's private data sources. Which solution will meet this requirement?",
        "options": [
            "A. Use a different FM",
            "B. Choose a lower temperature value",
            "C. Create an Amazon Bedrock knowledge base",
            "D. Enable model invocation logging"
        ],
        "answer": "C. Create an Amazon Bedrock knowledge base",
        "keywords": ["Amazon Titan", "private data", "knowledge base"],
        "explanation": "Creating a knowledge base allows the Amazon Titan FM to incorporate and utilize private data sources effectively."
    },
    {
        "question": "A company wants to develop an educational game where users answer questions such as the following: 'A jar contains six red, four green, and three yellow marbles. What is the probability of choosing a green marble from the jar?' Which solution meets these requirements with the LEAST operational overhead?",
        "options": [
            "A. Use supervised learning to create a regression model that will predict probability.",
            "B. Use reinforcement learning to train a model to return the probability.",
            "C. Use code that will calculate probability by using simple rules and computations.",
            "D. Use unsupervised learning to create a model that will estimate probability density."
        ],
        "answer": "C. Use code that will calculate probability by using simple rules and computations.",
        "keywords": ["educational game", "probability", "operational overhead"],
        "explanation": "Using simple rules and computations is the most efficient solution with the least operational overhead."
    },
    {
        "question": "Which functionality does Amazon SageMaker Clarify provide?",
        "options": [
            "A. Integrates a Retrieval Augmented Generation (RAG) workflow",
            "B. Monitors the quality of ML models in production",
            "C. Documents critical details about ML models",
            "D. Identifies potential bias during data preparation"
        ],
        "answer": "D. Identifies potential bias during data preparation",
        "keywords": ["Amazon SageMaker Clarify", "bias detection", "data preparation"],
        "explanation": "Amazon SageMaker Clarify is specifically designed to detect bias in data preparation and throughout the ML workflow."
    },
    {
        "question": "A company is building an ML model. The company collected new data and analyzed the data by creating a correlation matrix, calculating statistics, and visualizing the data. Which stage of the ML pipeline is the company currently in?",
        "options": [
            "A. Data pre-processing",
            "B. Feature engineering",
            "C. Exploratory data analysis",
            "D. Hyperparameter tuning"
        ],
        "answer": "C. Exploratory data analysis",
        "keywords": ["ML pipeline", "correlation matrix", "statistics", "data visualization"],
        "explanation": "Exploratory data analysis (EDA) is the stage where data is analyzed to discover patterns, spot anomalies, and visualize key relationships."
    },
    {
        "question": "A company has documents that are missing some words because of a database error. The company wants to build an ML model that can suggest potential words to fill in the missing text. Which type of model meets this requirement?",
        "options": [
            "A. Topic modeling",
            "B. Clustering models",
            "C. Prescriptive ML models",
            "D. BERT-based models"
        ],
        "answer": "D. BERT-based models",
        "keywords": ["missing words", "suggest text", "BERT"],
        "explanation": "BERT is a transformer-based model designed for natural language processing tasks like text prediction and completion."
    },
    {
        "question": "A company is building a chatbot to improve user experience. The company is using a large language model (LLM) from Amazon Bedrock for intent detection. The company wants to use few-shot learning to improve intent detection accuracy. Which additional data does the company need to meet these requirements?",
        "options": [
            "A. Pairs of chatbot responses and correct user intents",
            "B. Pairs of user messages and correct chatbot responses",
            "C. Pairs of user messages and correct user intents",
            "D. Pairs of user intents and correct chatbot responses"
        ],
        "answer": "C. Pairs of user messages and correct user intents",
        "keywords": ["LLM", "intent detection", "few-shot learning"],
        "explanation": "Few-shot learning improves model performance with a small number of examples. Providing user messages with corresponding intents is essential."
    },
    {
        "question": "A company is building a large language model (LLM) question answering chatbot. The company wants to decrease the number of actions call center employees need to take to respond to customer questions. Which business objective should the company use to evaluate the effect of the LLM chatbot?",
        "options": [
            "A. Website engagement rate",
            "B. Average call duration",
            "C. Corporate social responsibility",
            "D. Regulatory compliance"
        ],
        "answer": "B. Average call duration",
        "keywords": ["LLM chatbot", "business objective", "call duration"],
        "explanation": "Reducing the average call duration is a key metric to measure the effectiveness of a chatbot in improving efficiency."
    },
    {
        "question": "A company is using few-shot prompting on a base model that is hosted on Amazon Bedrock. The model currently uses 10 examples in the prompt. The model is invoked once daily and is performing well. The company wants to lower the monthly cost. Which solution will meet these requirements?",
        "options": [
            "A. Customize the model by using fine-tuning.",
            "B. Decrease the number of tokens in the prompt.",
            "C. Increase the number of tokens in the prompt.",
            "D. Use Provisioned Throughput."
        ],
        "answer": "B. Decrease the number of tokens in the prompt.",
        "keywords": ["few-shot prompting", "Amazon Bedrock", "cost reduction"],
        "explanation": "Reducing the number of tokens in a prompt decreases the cost associated with model invocation while maintaining performance."
    },
    {
        "question": "An accounting firm wants to implement a large language model (LLM) to automate document processing. The firm must proceed responsibly to avoid potential harms. What should the firm do when developing and deploying the LLM? (Select TWO.)",
        "options": [
            "A. Include fairness metrics for model evaluation.",
            "B. Adjust the temperature parameter of the model.",
            "C. Modify the training data to mitigate bias.",
            "D. Avoid overfitting on the training data.",
            "E. Apply prompt engineering techniques."
        ],
        "answer": ["A. Include fairness metrics for model evaluation.", "C. Modify the training data to mitigate bias."],
        "keywords": ["LLM", "responsible AI", "bias mitigation", "fairness metrics"],
        "explanation": "Including fairness metrics and modifying training data are critical steps to ensure responsible AI deployment and minimize potential harms."
    },
    {
        "question": "A company has built an image classification model to predict plant diseases from photos of plant leaves. The company wants to evaluate how many images the model classified correctly. Which evaluation metric should the company use to measure the model's performance?",
        "options": [
            "A. R-squared score",
            "B. Accuracy",
            "C. Root mean squared error (RMSE)",
            "D. Learning rate"
        ],
        "answer": "B. Accuracy",
        "keywords": ["image classification", "evaluation metric", "accuracy"],
        "explanation": "Accuracy measures the proportion of correct predictions made by the model, making it suitable for evaluating classification tasks."
    },
    {
        "question": "A large retailer receives thousands of customer support inquiries about products every day. The customer support inquiries need to be processed and responded to quickly. The company wants to implement Agents for Amazon Bedrock. What are the key benefits of using Amazon Bedrock agents that could help this retailer?",
        "options": [
            "A. Generation of custom foundation models (FMs) to predict customer needs",
            "B. Automation of repetitive tasks and orchestration of complex workflows",
            "C. Automatically calling multiple foundation models (FMs) and consolidating the results",
            "D. Selecting the foundation model (FM) based on predefined criteria and metrics"
        ],
        "answer": "B. Automation of repetitive tasks and orchestration of complex workflows",
        "keywords": ["Amazon Bedrock", "customer support", "automation", "workflows"],
        "explanation": "Amazon Bedrock agents streamline customer support by automating repetitive tasks and managing complex workflows."
    },
    {
        "question": "A company is training a foundation model (FM). The company wants to increase the accuracy of the model up to a specific acceptance level. Which solution will meet these requirements?",
        "options": [
            "A. Decrease the batch size.",
            "B. Increase the epochs.",
            "C. Decrease the epochs.",
            "D. Increase the temperature parameter."
        ],
        "answer": "B. Increase the epochs.",
        "keywords": ["foundation model", "accuracy", "epochs"],
        "explanation": "Increasing the number of epochs allows the model to learn more effectively from the training data, improving accuracy."
    },
    {
        "question": "A company has built a chatbot that can respond to natural language questions with images. The company wants to ensure that the chatbot does not return inappropriate or unwanted images. Which solution will meet these requirements?",
        "options": [
            "A. Implement moderation APIs.",
            "B. Retrain the model with a general public dataset.",
            "C. Perform model validation.",
            "D. Automate user feedback integration."
        ],
        "answer": "A. Implement moderation APIs.",
        "keywords": ["chatbot", "image moderation", "inappropriate content"],
        "explanation": "Moderation APIs help identify and filter out inappropriate or unwanted content, ensuring the chatbot returns suitable images."
    },
    {
        "question": "A law firm wants to build an AI application by using large language models (LLMs). The application will read legal documents and extract key points from the documents. Which solution meets these requirements?",
        "options": [
            "A. Build an automatic named entity recognition system.",
            "B. Create a recommendation engine.",
            "C. Develop a summarization chatbot.",
            "D. Develop a multi-language translation system."
        ],
        "answer": "C. Develop a summarization chatbot.",
        "keywords": ["LLM", "legal documents", "summarization"],
        "explanation": "A summarization chatbot can efficiently extract and present key points from legal documents, meeting the law firm's needs."
    },
    {
        "question": "A company wants to classify human genes into 20 categories based on gene characteristics. The company needs an ML algorithm to document how the inner mechanism of the model affects the output. Which ML algorithm meets these requirements?",
        "options": [
            "A. Decision trees",
            "B. Linear regression",
            "C. Logistic regression",
            "D. Neural networks"
        ],
        "answer": "A. Decision trees",
        "keywords": ["gene classification", "ML algorithm", "model interpretability"],
        "explanation": "Decision trees provide a transparent and interpretable model structure, allowing documentation of how inputs influence outputs."
    },
    {
        "question": "A company wants to develop a large language model (LLM) application by using Amazon Bedrock and customer data that is uploaded to Amazon S3. The company's security policy states that each team can access data for only the team's own customers. Which solution will meet these requirements?",
        "options": [
            "A. Create an Amazon Bedrock custom service role for each team that has access to only the team's customer data.",
            "B. Create a custom service role that has Amazon S3 access. Ask teams to specify the customer name on each Amazon Bedrock request.",
            "C. Redact personal data in Amazon S3. Update the S3 bucket policy to allow team access to customer data.",
            "D. Create one Amazon Bedrock role that has full Amazon S3 access. Create IAM roles for each team that have access to only each team's customer folders."
        ],
        "answer": "A. Create an Amazon Bedrock custom service role for each team that has access to only the team's customer data.",
        "keywords": ["Amazon Bedrock", "S3 data access", "team-level security"],
        "explanation": "Custom service roles restrict data access to specific teams, ensuring compliance with the company's security policy."
    },
    {
        "question": "A company wants to use a large language model (LLM) on Amazon Bedrock for sentiment analysis. The company wants to know how much information can fit into one prompt. Which consideration will inform the company's decision?",
        "options": [
            "A. Temperature",
            "B. Context window",
            "C. Batch size",
            "D. Model size"
        ],
        "answer": "B. Context window",
        "keywords": ["LLM", "sentiment analysis", "context window"],
        "explanation": "The context window determines the maximum amount of information the model can process in a single prompt."
    },
    {
        "question": "An AI practitioner has built a deep learning model to classify the types of materials in images. The AI practitioner now wants to measure the model performance. Which metric will help the AI practitioner evaluate the performance of the model?",
        "options": [
            "A. Confusion matrix",
            "B. Correlation matrix",
            "C. R2 score",
            "D. Mean squared error (MSE)"
        ],
        "answer": "A. Confusion matrix",
        "keywords": ["deep learning", "image classification", "model performance"],
        "explanation": "The confusion matrix evaluates classification performance by showing true positives, false positives, true negatives, and false negatives."
    },
    {
        "question": "An AI practitioner is building a model to generate images of humans in various professions. The AI practitioner discovered that the input data is biased and that specific attributes affect the image generation and create bias in the model. Which technique will solve the problem?",
        "options": [
            "A. Data augmentation for imbalanced classes",
            "B. Model monitoring for class distribution",
            "C. Retrieval Augmented Generation (RAG)",
            "D. Watermark detection for images"
        ],
        "answer": "A. Data augmentation for imbalanced classes",
        "keywords": ["image generation", "bias", "imbalanced data"],
        "explanation": "Data augmentation helps balance the dataset by artificially increasing underrepresented classes, reducing bias in image generation."
    },
    {
        "question": "A company is building an ML model to analyze archived data. The company must perform inference on large datasets that are multiple GBs in size. The company does not need to access the model predictions immediately. Which Amazon SageMaker inference option will meet these requirements?",
        "options": [
            "A. Batch transform",
            "B. Real-time inference",
            "C. Serverless inference",
            "D. Asynchronous inference"
        ],
        "answer": "A. Batch transform",
        "keywords": ["archived data", "large datasets", "inference"],
        "explanation": "Batch transform processes large datasets in bulk, making it ideal for scenarios where immediate access to predictions is unnecessary."
    },
    {
        "question": "A company needs to choose a model from Amazon Bedrock to use internally. The company must identify a model that generates responses in a style that the company's employees prefer. What should the company do to meet these requirements?",
        "options": [
            "A. Evaluate the models by using built-in prompt datasets.",
            "B. Evaluate the models by using a human workforce and custom prompt datasets.",
            "C. Use public model leaderboards to identify the model.",
            "D. Use the model InvocationLatency runtime metrics in Amazon CloudWatch when trying models."
        ],
        "answer": "B. Evaluate the models by using a human workforce and custom prompt datasets.",
        "keywords": ["Amazon Bedrock", "model evaluation", "preferred style"],
        "explanation": "Using a human workforce with custom prompts allows for evaluation that aligns with internal preferences and style."
    },
    {
        "question": "A company is using the Generative AI Security Scoping Matrix to assess security responsibilities for its solutions. The company has identified four different solution scopes based on the matrix. Which solution scope gives the company the MOST ownership of security responsibilities?",
        "options": [
            "A. Using a third-party enterprise application that has embedded generative AI features.",
            "B. Building an application by using an existing third-party generative AI foundation model (FM).",
            "C. Refining an existing third-party generative AI foundation model (FM) by fine-tuning the model by using data specific to the business.",
            "D. Building and training a generative AI model from scratch by using specific data that a customer owns."
        ],
        "answer": "D. Building and training a generative AI model from scratch by using specific data that a customer owns.",
        "keywords": ["security responsibilities", "generative AI", "ownership"],
        "explanation": "Building and training a model from scratch gives the company full control and ownership of the model and its security."
    },
    {
        "question": "A company uses Amazon SageMaker for its ML pipeline in a production environment. The company has large input data sizes up to 1 GB and processing times up to 1 hour. The company needs near real-time latency. Which SageMaker inference option meets these requirements?",
        "options": [
            "A. Real-time inference",
            "B. Serverless inference",
            "C. Asynchronous inference",
            "D. Batch transform"
        ],
        "answer": "A. Real-time inference",
        "keywords": ["SageMaker", "real-time latency", "large input data"],
        "explanation": "Real-time inference provides low latency for predictions, even with large input data sizes, meeting near real-time requirements."
    },
    {
        "question": "A company wants to use language models to create an application for inference on edge devices. The inference must have the lowest latency possible. Which solution will meet these requirements?",
        "options": [
            "A. Deploy optimized small language models (SLMs) on edge devices.",
            "B. Deploy optimized large language models (LLMs) on edge devices.",
            "C. Incorporate a centralized small language model (SLM) API for asynchronous communication with edge devices.",
            "D. Incorporate a centralized large language model (LLM) API for asynchronous communication with edge devices."
        ],
        "answer": "A. Deploy optimized small language models (SLMs) on edge devices.",
        "keywords": ["edge devices", "inference", "lowest latency"],
        "explanation": "Optimized small language models are lightweight and run efficiently on edge devices, minimizing latency."
    },
    {
        "question": "A company is building a contact center application and wants to gain insights from customer conversations. The company wants to analyze and extract key information from the audio of the customer calls. Which solution meets these requirements?",
        "options": [
            "A. Build a conversational chatbot by using Amazon Lex.",
            "B. Transcribe call recordings by using Amazon Transcribe.",
            "C. Extract information from call recordings by using Amazon SageMaker Model Monitor.",
            "D. Create classification labels by using Amazon Comprehend."
        ],
        "answer": "B. Transcribe call recordings by using Amazon Transcribe.",
        "keywords": ["contact center", "audio analysis", "customer conversations"],
        "explanation": "Amazon Transcribe converts audio to text, making it possible to analyze and extract insights from customer calls."
    },
    {
        "question": "A company wants to build an ML model by using Amazon SageMaker. The company needs to share and manage variables for model development across multiple teams. Which SageMaker feature meets these requirements?",
        "options": [
            "A. Amazon SageMaker Feature Store",
            "B. Amazon SageMaker Data Wrangler",
            "C. Amazon SageMaker Clarify",
            "D. Amazon SageMaker Model Cards"
        ],
        "answer": "A. Amazon SageMaker Feature Store",
        "keywords": ["SageMaker", "shared variables", "multiple teams"],
        "explanation": "The SageMaker Feature Store enables sharing and managing variables, promoting collaboration across teams."
    },
    {
        "question": "A company is using a pre-trained large language model (LLM) to build a chatbot for product recommendations. The company needs the LLM outputs to be short and written in a specific language. Which solution will align the LLM response quality with the company's expectations?",
        "options": [
            "A. Adjust the prompt.",
            "B. Choose an LLM of a different size.",
            "C. Increase the temperature.",
            "D. Increase the Top K value."
        ],
        "answer": "A. Adjust the prompt.",
        "keywords": ["LLM", "product recommendations", "response quality"],
        "explanation": "Adjusting the prompt ensures the LLM generates concise and contextually appropriate responses in the desired language."
    },
    {
        "question": "A company uses a foundation model (FM) from Amazon Bedrock for an AI search tool. The company wants to fine-tune the model to be more accurate by using the company's data. Which strategy will successfully fine-tune the model?",
        "options": [
            "A. Provide labeled data with the prompt field and the completion field.",
            "B. Prepare the training dataset by creating a .txt file that contains multiple lines in .csv format.",
            "C. Purchase Provisioned Throughput for Amazon Bedrock.",
            "D. Train the model on journals and textbooks."
        ],
        "answer": "A. Provide labeled data with the prompt field and the completion field.",
        "keywords": ["Amazon Bedrock", "fine-tuning", "labeled data"],
        "explanation": "Fine-tuning requires labeled data that maps input prompts to desired completions, enabling the model to adapt to specific tasks."
    },
    {
        "question": "An AI practitioner has a database of animal photos. The AI practitioner wants to automatically identify and categorize the animals in the photos without manual human effort. Which strategy meets these requirements?",
        "options": [
            "A. Object detection",
            "B. Anomaly detection",
            "C. Named entity recognition",
            "D. Inpainting"
        ],
        "answer": "A. Object detection",
        "keywords": ["animal photos", "automatic identification", "object detection"],
        "explanation": "Object detection is a computer vision technique used to identify and locate objects within an image, making it suitable for categorizing animals."
    },
    {
        "question": "A research company implemented a chatbot by using a foundation model (FM) from Amazon Bedrock. The chatbot searches for answers to questions from a large database of research papers. After multiple prompt engineering attempts, the company notices that the FM is performing poorly because of the complex scientific terms in the research papers. How can the company improve the performance of the chatbot?",
        "options": [
            "A. Use few-shot prompting to define how the FM can answer the questions.",
            "B. Use domain adaptation fine-tuning to adapt the FM to complex scientific terms.",
            "C. Change the FM inference parameters.",
            "D. Clean the research paper data to remove complex scientific terms."
        ],
        "answer": "B. Use domain adaptation fine-tuning to adapt the FM to complex scientific terms.",
        "keywords": ["Amazon Bedrock", "chatbot", "domain adaptation", "scientific terms"],
        "explanation": "Domain adaptation fine-tuning allows the FM to learn and adapt to domain-specific vocabulary, improving performance on complex scientific terms."
    },
    {
        "question": "A medical company deployed a disease detection model on Amazon Bedrock. To comply with privacy policies, the company wants to prevent the model from including personal patient information in its responses. The company also wants to receive notification when policy violations occur. Which solution meets these requirements?",
        "options": [
            "A. Use Amazon Macie to scan the model's output for sensitive data and set up alerts for potential violations.",
            "B. Configure AWS CloudTrail to monitor the model's responses and create alerts for any detected personal information.",
            "C. Use Guardrails for Amazon Bedrock to filter content. Set up Amazon CloudWatch alarms for notification of policy violations.",
            "D. Implement Amazon SageMaker Model Monitor to detect data drift and receive alerts when model quality degrades."
        ],
        "answer": "C. Use Guardrails for Amazon Bedrock to filter content. Set up Amazon CloudWatch alarms for notification of policy violations.",
        "keywords": ["Amazon Bedrock", "privacy policies", "Guardrails", "policy violations"],
        "explanation": "Guardrails for Amazon Bedrock help filter content to prevent sensitive information leakage, while CloudWatch alarms notify administrators of violations."
    },
    {
        "question": "An education provider is building a question and answer application that uses a generative AI model to explain complex concepts. The education provider wants to automatically change the style of the model response depending on who is asking the question. The education provider will give the model the age range of the user who has asked the question. Which solution meets these requirements with the LEAST implementation effort?",
        "options": [
            "A. Fine-tune the model by using additional training data that is representative of the various age ranges that the application will support.",
            "B. Add a role description to the prompt context that instructs the model of the age range that the response should target.",
            "C. Use chain-of-thought reasoning to deduce the correct style and complexity for a response suitable for that user.",
            "D. Summarize the response text depending on the age of the user so that younger users receive shorter responses."
        ],
        "answer": "B. Add a role description to the prompt context that instructs the model of the age range that the response should target.",
        "keywords": ["generative AI", "complex concepts", "age range", "prompt context"],
        "explanation": "Adding a role description to the prompt is a simple and effective way to tailor responses without additional training or adjustments."
    },
    {
        "question": "A social media company wants to use a large language model (LLM) for content moderation. The company wants to evaluate the LLM outputs for bias and potential discrimination against specific groups or individuals. Which data source should the company use to evaluate the LLM outputs with the LEAST administrative effort?",
        "options": [
            "A. User-generated content",
            "B. Moderation logs",
            "C. Content moderation guidelines",
            "D. Benchmark datasets"
        ],
        "answer": "D. Benchmark datasets",
        "keywords": ["LLM", "content moderation", "bias", "benchmark datasets"],
        "explanation": "Benchmark datasets are pre-defined and widely used for evaluating models, minimizing administrative effort."
    },
    {
        "question": "Which strategy evaluates the accuracy of a foundation model (FM) that is used in image classification tasks?",
        "options": [
            "A. Calculate the total cost of resources used by the model.",
            "B. Measure the model's accuracy against a predefined benchmark dataset.",
            "C. Count the number of layers in the neural network.",
            "D. Assess the color accuracy of images processed by the model."
        ],
        "answer": "B. Measure the model's accuracy against a predefined benchmark dataset.",
        "keywords": ["foundation model", "image classification", "accuracy evaluation"],
        "explanation": "Measuring accuracy against a benchmark dataset is the standard method for evaluating image classification models."
    },
    {
        "question": "A company has terabytes of data in a database that the company can use for business analysis. The company wants to build an AI-based application that can build a SQL query from input text that employees provide. The employees have minimal experience with technology. Which solution meets these requirements?",
        "options": [
            "A. Generative pre-trained transformers (GPT)",
            "B. Residual neural network",
            "C. Support vector machine",
            "D. WaveNet"
        ],
        "answer": "A. Generative pre-trained transformers (GPT)",
        "keywords": ["SQL query", "minimal experience", "generative AI"],
        "explanation": "GPT models can understand natural language inputs and generate SQL queries, making them suitable for this task."
    },
    {
        "question": "Which metric measures the runtime efficiency of operating AI models?",
        "options": [
            "A. Customer satisfaction score (CSAT)",
            "B. Training time for each epoch",
            "C. Average response time",
            "D. Number of training instances"
        ],
        "answer": "C. Average response time",
        "keywords": ["runtime efficiency", "AI models", "response time"],
        "explanation": "Average response time directly reflects the runtime efficiency of an AI model during inference."
    },
    {
        "question": "Which option is a benefit of ongoing pre-training when fine-tuning a foundation model (FM)?",
        "options": [
            "A. Helps decrease the model's complexity",
            "B. Improves model performance over time",
            "C. Decreases the training time requirement",
            "D. Optimizes model inference time"
        ],
        "answer": "B. Improves model performance over time",
        "keywords": ["ongoing pre-training", "fine-tuning", "performance improvement"],
        "explanation": "Ongoing pre-training enhances the model's understanding, leading to better performance in specific tasks over time."
    },
    {
        "question": "An AI practitioner wants to use a foundation model (FM) to design a search application. The search application must handle queries that have text and images. Which type of FM should the AI practitioner use to power the search application?",
        "options": [
            "A. Multi-modal embedding model",
            "B. Text embedding model",
            "C. Multi-modal generation model",
            "D. Image generation model"
        ],
        "answer": "A. Multi-modal embedding model",
        "keywords": ["search application", "text and images", "multi-modal"],
        "explanation": "Multi-modal embedding models are designed to handle both text and images, making them suitable for search applications."
    },
    {
        "question": "A company is using an Amazon Bedrock base model to summarize documents for an internal use case. The company trained a custom model to improve the summarization quality. Which action must the company take to use the custom model through Amazon Bedrock?",
        "options": [
            "A. Purchase Provisioned Throughput for the custom model.",
            "B. Deploy the custom model in an Amazon SageMaker endpoint for real-time inference.",
            "C. Register the model with the Amazon SageMaker Model Registry.",
            "D. Grant access to the custom model in Amazon Bedrock."
        ],
        "answer": "B. Deploy the custom model in an Amazon SageMaker endpoint for real-time inference.",
        "keywords": ["Amazon Bedrock", "custom model", "summarization"],
        "explanation": "Deploying the custom model on a SageMaker endpoint enables real-time inference through Amazon Bedrock."
    },
    {
        "question": "A company has built a solution by using generative AI. The solution uses large language models (LLMs) to translate training manuals from English into other languages. The company wants to evaluate the accuracy of the solution by examining the text generated for the manuals. Which model evaluation strategy meets these requirements?",
        "options": [
            "A. Bilingual Evaluation Understudy (BLEU)",
            "B. Root mean squared error (RMSE)",
            "C. Recall-Oriented Understudy for Gisting Evaluation (ROUGE)",
            "D. F1 score"
        ],
        "answer": "A. Bilingual Evaluation Understudy (BLEU)",
        "keywords": ["generative AI", "translation", "accuracy evaluation"],
        "explanation": "The BLEU metric is widely used for evaluating the quality of machine-translated text by comparing it to reference translations."
    },
    {
        "question": "How can companies use large language models (LLMs) securely on Amazon Bedrock?",
        "options": [
            "A. Design clear and specific prompts. Configure AWS Identity and Access Management (IAM) roles and policies by using least privilege access.",
            "B. Enable AWS Audit Manager for automatic model evaluation jobs.",
            "C. Enable Amazon Bedrock automatic model evaluation jobs.",
            "D. Use Amazon CloudWatch Logs to make models explainable and to monitor for bias."
        ],
        "answer": "A. Design clear and specific prompts. Configure AWS Identity and Access Management (IAM) roles and policies by using least privilege access.",
        "keywords": ["LLM security", "Amazon Bedrock", "IAM policies"],
        "explanation": "Using specific prompts and IAM policies with least privilege access minimizes security risks when deploying LLMs on Bedrock."
    },
    {
        "question": "A company is building a customer service chatbot. The company wants the chatbot to improve its responses by learning from past interactions and online resources. Which AI learning strategy provides this self-improvement capability?",
        "options": [
            "A. Supervised learning with a manually curated dataset of good responses and bad responses",
            "B. Reinforcement learning with rewards for positive customer feedback",
            "C. Unsupervised learning to find clusters of similar customer inquiries",
            "D. Supervised learning with a continuously updated FAQ database"
        ],
        "answer": "B. Reinforcement learning with rewards for positive customer feedback",
        "keywords": ["customer service chatbot", "self-improvement", "reinforcement learning"],
        "explanation": "Reinforcement learning uses a reward mechanism, such as positive customer feedback, to improve the chatbot's responses over time."
    },
    {
        "question": "A company wants to deploy a conversational chatbot to answer customer questions. The chatbot is based on a fine-tuned Amazon SageMaker JumpStart model. The application must comply with multiple regulatory frameworks. Which capabilities can the company show compliance for? (Select TWO.)",
        "options": [
            "A. Auto scaling inference endpoints",
            "B. Threat detection",
            "C. Data protection",
            "D. Cost optimization",
            "E. Loosely coupled microservices"
        ],
        "answer": ["B. Threat detection", "C. Data protection"],
        "keywords": ["SageMaker JumpStart", "compliance", "data protection", "threat detection"],
        "explanation": "Threat detection and data protection are essential for meeting regulatory frameworks, ensuring the chatbot's compliance with security standards."
    },
    {
        "question": "An e-commerce company wants to build a solution to determine customer sentiments based on written customer reviews of products. Which AWS services meet these requirements? (Select TWO.)",
        "options": [
            "A. Amazon Lex",
            "B. Amazon Comprehend",
            "C. Amazon Polly",
            "D. Amazon Bedrock",
            "E. Amazon Rekognition"
        ],
        "answer": ["B. Amazon Comprehend", "D. Amazon Bedrock"],
        "keywords": ["sentiment analysis", "customer reviews", "Comprehend", "Bedrock"],
        "explanation": "Amazon Comprehend specializes in sentiment analysis, while Amazon Bedrock provides foundation models for advanced text processing."
    },
    {
        "question": "A company wants to use a pre-trained generative AI model to generate content for its marketing campaigns. The company needs to ensure that the generated content aligns with the company's brand voice and messaging requirements. Which solution meets these requirements?",
        "options": [
            "A. Optimize the model's architecture and hyperparameters to improve the model's overall performance.",
            "B. Increase the model's complexity by adding more layers to the model's architecture.",
            "C. Create effective prompts that provide clear instructions and context to guide the model's generation.",
            "D. Select a large, diverse dataset to pre-train a new generative model."
        ],
        "answer": "C. Create effective prompts that provide clear instructions and context to guide the model's generation.",
        "keywords": ["generative AI", "marketing campaigns", "brand voice", "prompts"],
        "explanation": "Effective prompts guide the AI model to produce content that aligns with specific requirements, such as tone and messaging."
    },
    {
        "question": "A student at a university is copying content from generative AI to write essays. Which challenge of responsible generative AI does this scenario represent?",
        "options": [
            "A. Toxicity",
            "B. Hallucinations",
            "C. Plagiarism",
            "D. Privacy"
        ],
        "answer": "C. Plagiarism",
        "keywords": ["generative AI", "essay writing", "responsible AI"],
        "explanation": "Plagiarism refers to copying content without proper attribution, which is a significant ethical concern in AI usage."
    },
    {
        "question": "A company wants to make a chatbot to help customers. The chatbot will help solve technical problems without human intervention. The company chose a foundation model (FM) for the chatbot. The chatbot needs to produce responses that adhere to company tone. Which solution meets these requirements?",
        "options": [
            "A. Set a low limit on the number of tokens the FM can produce.",
            "B. Use batch inferencing to process detailed responses.",
            "C. Experiment and refine the prompt until the FM produces the desired responses.",
            "D. Define a higher number for the temperature parameter."
        ],
        "answer": "C. Experiment and refine the prompt until the FM produces the desired responses.",
        "keywords": ["chatbot", "foundation model", "technical problems"],
        "explanation": "Refining the prompt allows the FM to align its responses with the desired company tone and problem-solving style."
    },
    {
        "question": "A company has installed a security camera. The company uses an ML model to evaluate the security camera footage for potential thefts. The company has discovered that the model disproportionately flags people who are members of a specific ethnic group. Which type of bias is affecting the model output?",
        "options": [
            "A. Measurement bias",
            "B. Sampling bias",
            "C. Observer bias",
            "D. Confirmation bias"
        ],
        "answer": "B. Sampling bias",
        "keywords": ["ML model", "security footage", "bias"],
        "explanation": "Sampling bias occurs when the training data is not representative, leading to skewed predictions for certain groups."
    },
    {
        "question": "A company wants to use a large language model (LLM) on Amazon Bedrock for sentiment analysis. The company wants to classify the sentiment of text passages as positive or negative. Which prompt engineering strategy meets these requirements?",
        "options": [
            "A. Provide examples of text passages with corresponding positive or negative labels in the prompt followed by the new text passage to be classified.",
            "B. Provide a detailed explanation of sentiment analysis and how LLMs work in the prompt.",
            "C. Provide the new text passage to be classified without any additional context or examples.",
            "D. Provide the new text passage with a few examples of unrelated tasks, such as text summarization or question answering."
        ],
        "answer": "A. Provide examples of text passages with corresponding positive or negative labels in the prompt followed by the new text passage to be classified.",
        "keywords": ["sentiment analysis", "prompt engineering", "LLM"],
        "explanation": "Providing labeled examples in the prompt helps the LLM understand the task and improves classification accuracy."
    },
    {
        "question": "Which AWS service or feature can help an AI development team quickly deploy and consume a foundation model (FM) within the team's VPC?",
        "options": [
            "A. Amazon Personalize",
            "B. Amazon SageMaker JumpStart",
            "C. PartyRock, an Amazon Bedrock Playground",
            "D. Amazon SageMaker endpoints"
        ],
        "answer": "D. Amazon SageMaker endpoints",
        "keywords": ["foundation model", "VPC", "deployment"],
        "explanation": "SageMaker endpoints enable easy and secure deployment of foundation models within a VPC environment."
    },
    {
        "question": "A company has a database of petabytes of unstructured data from internal sources. The company wants to transform this data into a structured format so that its data scientists can perform machine learning (ML) tasks. Which service will meet these requirements?",
        "options": [
            "A. Amazon Lex",
            "B. Amazon Rekognition",
            "C. Amazon Kinesis Data Streams",
            "D. AWS Glue"
        ],
        "answer": "D. AWS Glue",
        "keywords": ["unstructured data", "structured format", "AWS Glue"],
        "explanation": "AWS Glue extracts and transforms unstructured data into a structured format, making it usable for ML tasks."
    },
    {
        "question": "A company has thousands of customer support interactions per day and wants to analyze these interactions to identify frequently asked questions and develop insights. Which AWS service can the company use to meet this requirement?",
        "options": [
            "A. Amazon Lex",
            "B. Amazon Comprehend",
            "C. Amazon Transcribe",
            "D. Amazon Translate"
        ],
        "answer": "B. Amazon Comprehend",
        "keywords": ["customer support", "text analysis", "frequently asked questions"],
        "explanation": "Amazon Comprehend performs natural language processing to extract insights and trends from large volumes of text."
    },
    {
        "question": "一家公司希望利用历史产品图像来为其产品图像分类定制卷标。以下哪些步骤的组合能满足这一要求？（select two）",
        "options": [
            "A. 在 Amazon Textract 中创建训练模型项目。",
            "B. 在 Amazon Rekognition 中创建训练模型项目。",
            "C. 将未标注的历史图像提供给模型训练。",
            "D. 按类别标记历史图像并将已标记的图像提供给模型训练。"
        ],
        "answer": ["B. 在 Amazon Rekognition 中创建训练模型项目。", "D. 按类别标记历史图像并将已标记的图像提供给模型训练。"],
        "keywords": ["Amazon Rekognition", "训练模型", "图像分类"],
        "explanation": "使用 Amazon Rekognition 创建训练模型项目，并提供经过标记的数据，能帮助模型准确学习分类任务。"
    },
    {
        "question": "哪种 AWS 服务可以检测存储于 PNG 格式的发票中的文本和手写内容？",
        "options": [
            "A. Amazon Polly",
            "B. Amazon Textract",
            "C. Amazon Kendra",
            "D. Amazon Comprehend"
        ],
        "answer": "B. Amazon Textract",
        "keywords": ["AWS 服务", "文本检测", "发票"],
        "explanation": "Amazon Textract 专为提取文件中的文本和数据而设计，特别是能处理带有结构化或非结构化内容的发票。"
    },
    {
        "question": "为了提高特定领域语音的转录准确性，应采用哪种解决方案？",
        "options": [
            "A. 在 Amazon Lex 中使用自定义机器人。",
            "B. 在 Amazon Translate 中使用自定义语言模型。",
            "C. 在 Amazon Transcribe 中使用批量语言识别。",
            "D. 在 Amazon Transcribe 中使用自定义语言模型。"
        ],
        "answer": "D. 在 Amazon Transcribe 中使用自定义语言模型。",
        "keywords": ["语音转录", "自定义语言模型", "Amazon Transcribe"],
        "explanation": "使用自定义语言模型可优化特定领域的语言特性，从而提升 Amazon Transcribe 的转录精度。"
    },
    {
        "question": "一家公司希望使用生成式 AI 为其网站创建产品描述。该公司应了解生成式 AI 的哪些局限性？",
        "options": [
            "A. 生成式 AI 模型可能会产生有偏见或不适当的内容，需要人工审查和编辑。",
            "B. 生成式 AI 无法处理产品描述所需的大量数据。",
            "C. 生成式 AI 无法生成电子商务网站所需的多语言文本。",
            "D. 生成式 AI 模型缺乏理解和整合产品规格与细节的能力。"
        ],
        "answer": "A. 生成式 AI 模型可能会产生有偏见或不适当的内容，需要人工审查和编辑。",
        "keywords": ["生成式 AI", "局限性", "人工审查"],
        "explanation": "生成式 AI 模型可能会因训练数据的多样性或缺陷而产生偏差输出，因此需要人工审核以确保适合用途。"
    },
    {
        "question": "一家公司拥有用于 AI 应用程序的容器化前端应用程序。该公司必须实施一个解决方案，以评估其 AWS 环境的安全状况，并识别潜在的安全漏洞（包括 Amazon EC2 实例和 Amazon Elastic Container Registry (ECR) 存储库）。该解决方案还应提供修复建议。哪项 AWS 服务可以满足这些要求？",
        "options": [
            "A. AWS CloudTrail",
            "B. AWS Config",
            "C. Amazon Inspector",
            "D. AWS Artifact"
        ],
        "answer": "C. Amazon Inspector",
        "keywords": ["安全服务", "漏洞评估", "Amazon Inspector"],
        "explanation": "Amazon Inspector 可自动评估 AWS 资源中的漏洞，并提供修复建议，特别适用于 EC2 和 ECR。"
    },
    {
        "question": "在生成式 AI 的背景下，什么是基础模型（Foundation Model, FM）？",
        "options": [
            "A. 一个针对财务或医疗等狭窄领域训练的任务专用模型，可作为该领域的基础。",
            "B. 一个大型通用模型，预先在多样化数据集上训练，并可针对下游任务进行微调。",
            "C. 用于理解不同模型如何学习表示的理论框架。",
            "D. 作为设计更复杂神经网络的起点的基本架构。"
        ],
        "answer": "B. 一个大型通用模型，预先在多样化数据集上训练，并可针对下游任务进行微调。",
        "keywords": ["生成式 AI", "基础模型", "通用模型"],
        "explanation": "基础模型是一种通用模型，通常在多样化数据上预训练，具有广泛适应性，并可用于特定任务的微调。"
    },
    {
        "question": "指令式微调（Instruction-based Fine-tuning）的有效数据格式是什么？",
        "options": [
            "A. 按类别标记的图像",
            "B. 精选推荐音乐的播放列表",
            "C. 提示-响应文本对",
            "D. 带有转录的音频文件"
        ],
        "answer": "C. 提示-响应文本对",
        "keywords": ["微调", "指令式", "数据格式"],
        "explanation": "指令式微调使用提示和响应对的标记示例，以改进预训练基础模型在特定任务上的性能。"
    },
    {
        "question": "一家公司正在 AWS 上部署解决方案，以使用语义搜索功能增强其知识库，并计划将该解决方案与 Amazon Bedrock 集成。该公司可以使用哪项 AWS 服务来保护对 Amazon Bedrock 的访问？",
        "options": [
            "A. Amazon Macie",
            "B. Amazon Rekognition",
            "C. AWS 身份与访问管理（IAM）",
            "D. AWS Config"
        ],
        "answer": "C. AWS 身份与访问管理（IAM）",
        "keywords": ["AWS 服务", "访问控制", "Amazon Bedrock"],
        "explanation": "AWS IAM 提供基于身份验证和资源级别访问控制的安全机制，用于保护 Amazon Bedrock 的访问。"
    },
    {
        "question": "一家金融公司希望使用开源基础模型（Foundation Model, FM）来评估信用合同是否符合合规规则，并减少人工审核的工作量。哪项 AWS 服务可以满足这些要求？",
        "options": [
            "A. Amazon SageMaker JumpStart",
            "B. Amazon Textract",
            "C. Amazon Kendra",
            "D. Amazon Q Business"
        ],
        "answer": "A. Amazon SageMaker JumpStart",
        "keywords": ["AWS 服务", "信用合同", "基础模型"],
        "explanation": "Amazon SageMaker JumpStart 提供预训练的基础模型和解决方案，适合用于快速部署和评估特定业务需求。"
    },
    {
        "question": "请按从「最低延迟」到「最高延迟」的顺序排列以下 Amazon SageMaker 推理选项（select two plus one）。",
        "options": [
            "A. 批量转换（Batch transform）",
            "B. 实时推理（Real-time inference）",
            "C. 异步推理（Asynchronous inference）"
        ],
        "answer": ["B. 实时推理（Real-time inference）", "C. 异步推理（Asynchronous inference）", "A. 批量转换（Batch transform）"],
        "keywords": ["Amazon SageMaker", "推理选项", "延迟顺序"],
        "explanation": "实时推理适用于低延迟需求，异步推理适合更大数据集，批量转换用于脱机处理。"
    },
    {
        "question": "一个数据科学团队希望改进模型性能，计划增加训练数据集中的变量数量，并修改算法行为。\n以下哪些机器学习管道步骤可以满足这些需求？（select two）",
        "options": [
            "A. 超参数调优（Hyperparameter tuning）",
            "B. 模型评估（Model evaluation）",
            "C. 特征工程（Feature engineering）",
            "D. 模型监控（Model monitoring）",
            "E. 数据收集（Data collection）"
        ],
        "answer": ["C. 特征工程（Feature engineering）", "A. 超参数调优（Hyperparameter tuning）"],
        "keywords": ["改进模型性能", "变量数量", "算法行为"],
        "explanation": "特征工程可以通过增加变量数量来增强模型的输入，而超参数调优则能修改算法的行为以提高性能。"
    },
    {
        "question": "一家公司希望通过提供外部知识源来提高大语言模型（LLM）生成响应的一致性和质量。\n哪种技术能以最少的开发工作量满足这一需求？",
        "options": [
            "A. 微调（Fine-tuning）",
            "B. 检索增强生成（Retrieval-Augmented Generation, RAG）",
            "C. 基于上下文学习（In-context learning）",
            "D. 提示工程（Prompt engineering）"
        ],
        "answer": "B. 检索增强生成（Retrieval-Augmented Generation, RAG）",
        "keywords": ["大语言模型", "一致性", "质量", "外部知识源"],
        "explanation": "RAG 通过将模型与外部知识库集成，使模型能生成更准确的响应，并且开发成本较低。"
    },
    {
        "question": "一家公司正在使用基础模型（FM）构建生成式 AI 应用程序。该公司决定使用专有数据集定制自己的 FM，而不是使用预训练模型。定制 FM 有哪些权衡？（select two）",
        "options": [
            "A. 增加幻觉风险（Hallucination risk）",
            "B. 降低准确性",
            "C. 更高的延迟",
            "D. 更高的成本",
            "E. 更高的实现复杂性"
        ],
        "answer": ["D. 更高的成本", "E. 更高的实现复杂性"],
        "keywords": ["生成式 AI", "基础模型", "定制"],
        "explanation": "定制模型需要更多计算资源和数据管理，因此会增加成本和实现复杂性。"
    },
    {
        "question": "一家公司希望记录对 Amazon Bedrock 的 API 调用，以满足合规要求。这些日志需包括 API 调用、调用用户及调用时间。哪项 AWS 服务可以满足这些要求？",
        "options": [
            "A. Amazon Inspector",
            "B. Amazon CloudWatch",
            "C. AWS Trusted Advisor",
            "D. AWS CloudTrail"
        ],
        "answer": "D. AWS CloudTrail",
        "keywords": ["Amazon Bedrock", "API 调用", "日志", "合规"],
        "explanation": "AWS CloudTrail 是专为监控和记录 AWS 账户中的 API 调用设计的服务，能提供合规所需的详细信息。"
    },
    {
        "question": "一家旅游公司希望使用预训练的生成式 AI 模型来生成用于营销材料的背景图像。该公司缺乏机器学习专业知识，且不希望定制和托管机器学习模型。哪项 AWS 服务可以满足这些需求？",
        "options": [
            "A. Amazon Bedrock",
            "B. Amazon SageMaker JumpStart",
            "C. Amazon Rekognition",
            "D. Amazon Personalize"
        ],
        "answer": "A. Amazon Bedrock",
        "keywords": ["生成式 AI", "预训练", "背景图像", "营销材料"],
        "explanation": "Amazon Bedrock 是一项完全托管的服务，提供统一的 API 来访问流行的基础模型，无需训练或管理模型即可使用。"
    },
    {
        "question": "一家使用 Amazon SageMaker 进行机器学习模型管理的公司希望为模型所有者创建一个解决方案，以记录模型信息（包括预期用途、风险评级、训练细节和评估结果）。哪项 SageMaker 功能可以满足这些需求？",
        "options": [
            "A. SageMaker Role Manager",
            "B. SageMaker Model Cards",
            "C. SageMaker Model Dashboard",
            "D. SageMaker Model Monitor"
        ],
        "answer": "B. SageMaker Model Cards",
        "keywords": ["SageMaker", "模型管理", "记录模型信息"],
        "explanation": "SageMaker Model Cards 是一个记录和文档化机器学习模型详细信息的工具，支持透明和可解释的模型开发。"
    },
    {
        "question": "请从以下列表中为每个任务选择正确的 AWS 服务或功能（每项 AWS 服务或功能应选择一个或多个，select two plus three）。\n任务列表：1.实施身份验证和资源级别访问控制。2.在生成式 AI 应用程序中设置避免特定主题的策略。3.基于定义的分类阈值过滤有害内容。4.定义用户角色和访问 Amazon Bedrock 的权限。5.监控和分析用户输入以确保符合安全政策。",
        "options": [
            "A. Amazon Bedrock 的安全防护措施（Guardrails for Amazon Bedrock）",
            "A. Amazon Bedrock 的安全防护措施（Guardrails for Amazon Bedrock）",
            "A. Amazon Bedrock 的安全防护措施（Guardrails for Amazon Bedrock）",
            "B. AWS 身份与访问管理（IAM）",
            "B. AWS 身份与访问管理（IAM）"

        ],
        "answer": ["B. AWS 身份与访问管理（IAM）", "A. Amazon Bedrock 的安全防护措施（Guardrails for Amazon Bedrock）", "A. Amazon Bedrock 的安全防护措施（Guardrails for Amazon Bedrock）", "B. AWS 身份与访问管理（IAM）", "A. Amazon Bedrock 的安全防护措施（Guardrails for Amazon Bedrock）"],
        "keywords": ["AWS 服务", "生成式 AI", "安全", "访问控制"],
        "explanation": "正确组合的服务可以实现访问控制、安全防护以及符合政策要求的监控。"
    },
    {
        "question": "一家公司希望评估生成文本的基础模型（FM）的性能。哪种技术或指标可以满足这些需求？",
        "options": [
            "A. 强化学习（Reinforcement learning）",
            "B. F1 分数（F1 score）",
            "C. 基于摘要生成的回忆导向评估（ROUGE）",
            "D. 微调（Fine-tuning）"
        ],
        "answer": "C. 基于摘要生成的回忆导向评估（ROUGE）",
        "keywords": ["生成文本", "基础模型", "评估性能"],
        "explanation": "ROUGE 是一种用于评估文本生成和摘要生成质量的指针，能有效衡量模型生成内容与参考内容的相似性。"
    },
    {
        "question": "一家营销公司希望为其电子商务客户的网站生成个性化的产品描述。哪种提示工程技术能以最少的运营工作量满足这些需求？",
        "options": [
            "A. 使用几次示例的提示（Few-shot prompting）",
            "B. 无需示例的零次提示（Zero-shot prompting）",
            "C. 根据客户参与度指标优化描述的微调（Fine-tuning）",
            "D. 在不同领域继续预训练（Continued pre-training）"
        ],
        "answer": "A. 使用几次示例的提示（Few-shot prompting）",
        "keywords": ["营销", "提示工程", "产品描述"],
        "explanation": "Few-shot prompting 使用示例帮助模型学习所需的描述格式和风格，既快速又高效。"
    },
    {
    "question": "一名数据科学家发现某个模型在训练数据上的准确性很高，但在测试数据上的准确性较低。这种现象是什么？",
    "options": [
        "A. 训练时间不足",
        "B. 欠拟合（Underfitting）",
        "C. 训练数据过多",
        "D. 过拟合（Overfitting）"
    ],
    "answer": "D. 过拟合（Overfitting）",
    "keywords": ["训练数据", "测试数据", "准确性", "过拟合"],
    "explanation": "过拟合是指模型对训练数据学习过度，导致对测试数据的泛化能力较差。"
    },
    {
        "question": "人类利用智慧可以操控什么？",
        "options": [
            "A. 环境（Environment）",
            "B. 空间（Space）",
            "C. 目标（Objective）",
            "D. 任务（Mission）"
        ],
        "answer": "A. 环境（Environment）",
        "keywords": ["智慧", "操控", "环境"],
        "explanation": "人类通过智能操控环境，以实现目标并完成任务，包括建造工具、建筑物以及解决各种问题的策略。"
    },
    {
        "question": "反射代理（Reflex Agents）和基于模型的反射代理（Model-based Reflex Agents）是什么的类型？",
        "options": [
            "A. 机器人（Robot）",
            "B. 人工智能代理（Artificial Intelligent Agents）",
            "C. 算法（Algorithms）",
            "D. 编译程序（Compilers）"
        ],
        "answer": "B. 人工智能代理（Artificial Intelligent Agents）",
        "keywords": ["反射代理", "基于模型", "人工智能代理"],
        "explanation": "人工智能代理是一种设计用于模仿人类行为的计算系统，反射代理基于当前环境条件进行动作，而基于模型的代理则使用环境模型来做出决策。"
    },
    {
        "question": "根据人工智能伦理指南，「自主原则」（Principle of Autonomy）是什么意思？",
        "options": [
            "A. 机器人拥有自由意志",
            "B. 人工智能代理的行为如同人类",
            "C. 人工智能系统将以人为中心",
            "D. 人工智能系统将保持人类自主权"
        ],
        "answer": "D. 人工智能系统将保持人类自主权",
        "keywords": ["人工智能伦理", "自主原则", "人类自主权"],
        "explanation": "自主原则要求人工智能系统的设计应保留人类的决策权，确保人工智能不能在未经人类许可的情况下行动。"
    },
    {
        "question": "以人为中心的可信人工智能需要什么？",
        "options": [
            "A. 通过质量保证认证",
            "B. 持续评估和监控",
            "C. 财务上可持续发展",
            "D. 经过人类测试"
        ],
        "answer": "B. 持续评估和监控",
        "keywords": ["可信人工智能", "以人为中心", "评估和监控"],
        "explanation": "可信人工智能需要持续监控以确保其行为安全并符合伦理标准，这包括定期进行测试和审查。"
    },
    {
        "question": "可持续发展关注于哪三个核心领域？",
        "options": [
            "A. 科学、环境与经济",
            "B. 社会、经济与环境",
            "C. 社会、经济与创业",
            "D. 社会、创业与环境"
        ],
        "answer": "B. 社会、经济与环境",
        "keywords": ["可持续发展", "核心领域", "社会", "经济", "环境"],
        "explanation": "可持续发展包含社会、经济与环境三个核心领域，目标是满足当代需求的同时，不损害后代的发展能力。"
    },
    {
        "question": "欧盟和联合国将为所有人设计列为核心原则。这种类型的设计被称为什么？",
        "options": [
            "A. 核心设计（Core design）",
            "B. 通用设计（Universal design）",
            "C. 生物亲和设计（Biophilic design）",
            "D. 乌托邦设计（Utopic design）"
        ],
        "answer": "B. 通用设计（Universal design）",
        "keywords": ["通用设计", "无障碍性", "核心原则"],
        "explanation": "通用设计考虑所有人的需求，强调无障碍性、可用性和包容性，适合各种年龄、能力和身体状况的人群。"
    },
    {
        "question": "人工智能对于第四次工业革命快速发展的主要贡献是什么？",
        "options": [
            "A. 增强设计（Enhanced design）",
            "B. 自动化（Automation）",
            "C. 大数据（Big Data）",
            "D. 人工智能个人助理（AI personal assistants）"
        ],
        "answer": "B. 自动化（Automation）",
        "keywords": ["第四次工业革命", "人工智能", "自动化"],
        "explanation": "人工智能技术的自动化能力显著提升了业务和工业流程的速度、效率和准确性，是第四次工业革命的主要推动力。"
    },
    {
        "question": "谁是计算器编程的先驱？",
        "options": [
            "A. 温迪·霍尔（Dame Wendy Hall）",
            "B. 凯伦·斯帕克·琼斯（Karen Spark Jones）",
            "C. 埃达·洛芙莱斯（Ada Lovelace）",
            "D. 索菲·威尔逊（Sophie Wilson）"
        ],
        "answer": "C. 埃达·洛芙莱斯（Ada Lovelace）",
        "keywords": ["计算器编程", "先驱", "埃达·洛芙莱斯"],
        "explanation": "埃达·洛芙莱斯被广泛认为是计算器编程的先驱，她在 1842 年首次提出算法概念，并描述了计算器的潜力。"
    },
    {
        "question": "一家公司希望根据基因特征将人类基因分类为 20 个类别。该公司需要一种机器学习算法，能够记录模型内部机制如何影响输出。哪种机器学习算法可以满足这些需求？",
        "options": [
            "A. 判定树（Decision Trees）",
            "B. 线性回归（Linear Regression）",
            "C. 逻辑回归（Logistic Regression）",
            "D. 神经网络（Neural Networks）"
        ],
        "answer": "A. 判定树（Decision Trees）",
        "keywords": ["基因分类", "机器学习", "模型机制"],
        "explanation": "判定树具有高度解释性，能够帮助理解模型的内部机制（例如特征的重要性），适用于该需求。"
    },
    {
        "question": "一个人工智能代理依赖于其感知输入，这被称为什么？",
        "options": [
            "A. 位置（Position）",
            "B. 环境（Environment）",
            "C. 世界（World）",
            "D. 感知（Percept）"
        ],
        "answer": "D. 感知（Percept）",
        "keywords": ["人工智能代理", "感知输入"],
        "explanation": "感知是指代理当前的感知输入，是代理用来做出决策的基础数据。"
    },
    {
        "question": "基于代理的模型是一种仿真自主代理（个体和集体）的方法。可以用什么来从仿真生成的数据中学习？",
        "options": [
            "A. Paraview",
            "B. 机器学习（Machine Learning）",
            "C. Python",
            "D. 电子表格（Spreadsheet）"
        ],
        "answer": "B. 机器学习（Machine Learning）",
        "keywords": ["代理模型", "仿真数据", "机器学习"],
        "explanation": "机器学习可以从仿真生成的数据中识别模式，用于优化代理的决策和行动。"
    },
    {
        "question": "一家律师事务所希望使用大语言模型（LLM）构建一个应用程序，用于阅读法律文档并提取关键要点。哪种解决方案可以满足这些需求？",
        "options": [
            "A. 建立一个自动命名实体识别系统",
            "B. 创建一个推荐引擎",
            "C. 开发一个摘要生成聊天机器人",
            "D. 开发一个多语言翻译系统"
        ],
        "answer": "C. 开发一个摘要生成聊天机器人",
        "keywords": ["法律文档", "大语言模型", "摘要生成"],
        "explanation": "摘要生成聊天机器人专注于从文档中提取关键信息，适用于处理法律文档的场景。"
    },
    {
        "question": "计算器科学家和经济学家使用什么术语来描述一个代理的「幸福感」？",
        "options": [
            "A. 指数（Index）",
            "B. 温暖感（Warm）",
            "C. 回报（Return）",
            "D. 效用（Utility）"
        ],
        "answer": "D. 效用（Utility）",
        "keywords": ["代理", "幸福感", "效用"],
        "explanation": "效用是衡量代理对特定结果满意程度的指针，用于决定代理采取最佳行动以最大化满意度。"
    },
    {
        "question": "机器学习如何使机器人具备自主性？",
        "options": [
            "A. 使用光学字符识别（OCR）阅读文档",
            "B. 使用自然语言处理（NLP）进行语音处理",
            "C. 使用执行器改变其环境",
            "D. 从传感器数据中学习并计划完成任务"
        ],
        "answer": "D. 从传感器数据中学习并计划完成任务",
        "keywords": ["机器人", "机器学习", "自主性"],
        "explanation": "通过学习传感器数据并生成计划，机器人可以对环境做出反应，执行自主决策。"
    },
    {
        "question": "什么被定义为能自动执行一系列复杂任务的机器？",
        "options": [
            "A. 机器人（Robot）",
            "B. 生产线（Production Line）",
            "C. 计算器（Computer）",
            "D. 自主车辆（Autonomous Vehicle）"
        ],
        "answer": "C. 计算器（Computer）",
        "keywords": ["复杂任务", "自动执行", "计算器"],
        "explanation": "计算器能快速准确地处理大量数据，用于多种应用，包括人工智能、自动化和生产线。"
    },
    {
        "question": "什么被定义为一组特定问题的方法或假设？",
        "options": [
            "A. 方法（Approach）",
            "B. 集合（Set）",
            "C. 范式（Paradigm）",
            "D. 算法（Algorithm）"
        ],
        "answer": "C. 范式（Paradigm）",
        "keywords": ["定义", "假设", "方法"],
        "explanation": "范式为问题解决提供结构和框架，用于更好地理解问题并开发解决方案。"
    },
    {
        "question": "智能机器人使用人工智能做什么？",
        "options": [
            "A. 感知、计划和行动（Sense, plan and act）",
            "B. 计划、行动和讲话（Plan, act and speak）",
            "C. 感知、计划和行动（Perceive, plan and act）",
            "D. 感知、计划和移动（Sense, plan and move）"
        ],
        "answer": "C. 感知、计划和行动（Perceive, plan and act）",
        "keywords": ["智能机器人", "人工智能", "感知"],
        "explanation": "智能机器人利用 AI 感知环境、规划行动并执行任务，这是一个基本的「感知-计划-行动」过程。"
    },
    {
        "question": "什么是智能机器人？",
        "options": [
            "A. 拥有意识的机器人",
            "B. 行为像人类的机器人",
            "C. 使用人工智能技术的机器人",
            "D. 代替人类工作的机器人"
        ],
        "answer": "C. 使用人工智能技术的机器人",
        "keywords": ["智能机器人", "定义", "人工智能"],
        "explanation": "智能机器人使用人工智能技术（如机器学习和自然语言处理）来感知环境、规划行动并完成任务。"
    },
    {
        "question": "一家公司开发了一个聊天机器人，能用自然语言回答问题并返回图片。该公司希望确保聊天机器人不返回不适当或不需要的图片。哪种解决方案可以满足这些需求？",
        "options": [
            "A. 实施内容审核 API（Moderation APIs）",
            "B. 使用通用公共数据集重新训练模型",
            "C. 执行模型验证",
            "D. 自动整合用户反馈"
        ],
        "answer": "A. 实施内容审核 API（Moderation APIs）",
        "keywords": ["聊天机器人", "内容审核", "图片"],
        "explanation": "内容审核 API 可过滤图片内容，确保返回的图片符合规范并避免不适当内容。"
    },
    {
        "question": "一家公司正在训练一个基础模型（FM），希望将模型的准确性提升到特定的接受水平。哪种解决方案可以满足这些需求？",
        "options": [
            "A. 减少批量大小（Batch size）",
            "B. 增加训练迭代次数（Epochs）",
            "C. 减少训练迭代次数（Epochs）",
            "D. 增加温度参数（Temperature parameter）"
        ],
        "answer": "B. 增加训练迭代次数（Epochs）",
        "keywords": ["基础模型", "准确性", "训练迭代"],
        "explanation": "增加训练迭代次数可以帮助模型更充分地学习数据特征，从而提高准确性。"
    },
    {
        "question": "一家大型零售商每天收到数千条有关产品的客户支持查询，这些查询需要快速处理和响应。该公司希望实施适用于 Amazon Bedrock 的代理。使用 Amazon Bedrock 代理的主要好处是什么？",
        "options": [
            "A. 生成自定义基础模型（FM），以预测客户需求",
            "B. 自动化重复任务并协调复杂工作流程",
            "C. 自动调用多个基础模型并整合结果",
            "D. 基于预定义标准和指针选择基础模型"
        ],
        "answer": "B. 自动化重复任务并协调复杂工作流程",
        "keywords": ["Amazon Bedrock", "代理", "工作流程"],
        "explanation": "Amazon Bedrock 的代理可以自动处理重复性任务，并协调工作流程，大幅提高效率。"
    },
    {
        "question": "一家公司构建了一个图像分类模型，用于预测植物叶片照片中的植物疾病。该公司希望评估模型正确分类的图片数量。应使用哪种评估指针来测量模型性能？",
        "options": [
            "A. R 平方分数（R-squared score）",
            "B. 准确率（Accuracy）",
            "C. 均方根误差（Root Mean Squared Error, RMSE）",
            "D. 学习率（Learning Rate）"
        ],
        "answer": "B. 准确率（Accuracy）",
        "keywords": ["图像分类", "植物疾病", "模型性能"],
        "explanation": "准确率是一种评估模型正确分类输入数据的能力的基本指标。"
    },
    {
        "question": "一家会计师事务所希望实施一个大语言模型（LLM）来自动化文档处理。该事务所必须负责任地开发和部署 LLM，以避免潜在的危害。在开发和部署 LLM 时应该采取哪些措施？（select two）",
        "options": [
            "A. 包括公平性指针以评估模型",
            "B. 调整模型的温度参数",
            "C. 修改训练数据以减轻偏见",
            "D. 避免在训练数据中出现过拟合",
            "E. 应用提示工程技术（Prompt engineering）"
        ],
        "answer": ["A. 包括公平性指针以评估模型", "C. 修改训练数据以减轻偏见"],
        "keywords": ["大语言模型", "文档处理", "公平性", "偏见"],
        "explanation": "包括公平性指针和修改训练数据以减轻偏见，可以确保模型在应用过程中更为公平和负责。"
    },
    {
        "question": "一家公司正在开发一个模型，根据各种特征（如尺寸、重量、品牌和制造日期）来预测产品价格。哪种机器学习方法最适合此任务？",
        "options": [
            "A. 分类",
            "B. 回归",
            "C. 聚类",
            "D. 维度缩减"
        ],
        "answer": "B. 回归",
        "keywords": ["回归", "连续数值预测"],
        "explanation": "回归用于预测连续数值，而分类用于预测分类结果；聚类将类似数据点分组，而维度缩减是减少特征数量。"
    },
    {
        "question": "一家公司正在扩大对人工智能的应用，应该优先考虑哪项核心原则，以建立 AI 开发和使用的清晰指导、监督和问责机制？",
        "options": [
            "A. 偏见预防",
            "B. 准确性与可靠性",
            "C. 数据保护与安全",
            "D. 治理"
        ],
        "answer": "D. 治理",
        "keywords": ["治理", "监督", "问责机制"],
        "explanation": "治理涵盖管理 AI 系统的整体框架，包括政策、流程和决策机制。"
    },
    {
        "question": "一家公司开始在 AWS 上使用生成式 AI，为确保负责任的 AI 实践，哪种工具可以为其提供指导和信息？",
        "options": [
            "A. AWS 市场",
            "B. AWS AI 服务卡",
            "C. SageMaker",
            "D. Bedrock"
        ],
        "answer": "B. AWS AI 服务卡",
        "keywords": ["生成式 AI", "服务卡", "指导"],
        "explanation": "AWS AI 服务卡提供有关特定 AWS 服务的详细信息，包括使用案例、限制及负责任的设计考虑。"
    },
    {
        "question": "机器学习中的特征工程的主要目的是什么？",
        "options": [
            "A. 确保模型的稳定性能",
            "B. 评估模型的性能",
            "C. 收集和预处理数据特征",
            "D. 转换数据并创建模型所需的变量或特征"
        ],
        "answer": "D. 转换数据并创建模型所需的变量或特征",
        "keywords": ["特征工程", "数据转换", "变量创建"],
        "explanation": "特征工程的目的是转换数据并为模型创建特征，供模型更好地学习和使用。"
    },
    {
        "question": "一家小公司希望使用机器学习来预测客户流失，但缺乏专门的数据科学团队。哪种 AWS 工具可以帮助他们轻松地构建模型而无需大量编码？",
        "options": [
            "A. Amazon SageMaker JumpStart",
            "B. SageMaker Studio",
            "C. SageMaker Canvas",
            "D. SageMaker Pipelines"
        ],
        "answer": "C. SageMaker Canvas",
        "keywords": ["无代码", "客户流失预测", "SageMaker Canvas"],
        "explanation": "SageMaker Canvas 是一种无代码工具，可以帮助用户轻松构建机器学习模型。"
    },
    {
            "question": "一家金融机构正在开发欺诈检测模型，项目负责人宣布将使用 MLOps。在此项目背景下，如何解释 MLOps？",
            "options": [
                "A. 用于可视化机器学习模型性能的工具",
                "B. 用于管理机器学习系统全生命周期的一组实践",
                "C. 用于在生产环境中部署和维护机器学习模型的流程",
                "D. 构建和训练机器学习模型的框架"
            ],
            "answer": "B. 用于管理机器学习系统全生命周期的一组实践",
            "keywords": ["MLOps", "全生命周期", "管理实践"],
            "explanation": "MLOps 是管理机器学习模型全生命周期的一组实践，涵盖了模型的开发、部署、监控和维护。"
    },
    {
        "question": "哪种 AWS 服务可用于创建基于知识的聊天机器人，能够根据公司内部文件回答有关产品和服务的问题？",
        "options": [
            "A. Amazon SageMaker",
            "B. Amazon Q Business",
            "C. Amazon Polly",
            "D. Amazon Rekognition"
        ],
        "answer": "B. Amazon Q Business",
        "keywords": ["AWS 服务", "聊天机器人", "知识库"],
        "explanation": "Amazon Q Business 允许企业创建智能聊天机器人，并能够基于公司内部文件回答问题。"
    },
    {
        "question": "开发团队需要选择一种服务来存储和查询向量嵌入，哪种 AWS 服务最适合此需求？",
        "options": [
            "A. Glue Data Catalog",
            "B. Amazon S3",
            "C. Redshift",
            "D. OpenSearch Service"
        ],
        "answer": "D. OpenSearch Service",
        "keywords": ["向量嵌入", "存储", "查询"],
        "explanation": "OpenSearch 支持基于向量的存储和查询，是满足此需求的最佳服务。"
    },
    {
        "question": "一家公司希望评估 AWS 服务的安全性和合规性实践，这些服务是供销售 AI 产品的厂商使用的。哪项 AWS 服务可以帮助他们访问 AWS 合规性报告和证书？",
        "options": [
            "A. AWS Organizations",
            "B. Amazon Inspector",
            "C. AWS CloudTrail",
            "D. AWS Artifact"
        ],
        "answer": "D. AWS Artifact",
        "keywords": ["安全性", "合规性", "报告和证书"],
        "explanation": "AWS Artifact 提供集中式的 AWS 合规性报告和证书，适用于此需求。"
    },
    {
        "question": " 一个机器学习模型在训练数据上表现良好，但在新数据上表现不佳，可能的问题是什么？",
        "options": [
            "A. 过拟合",
            "B. 欠拟合",
            "C. 训练数据不足",
            "D. 数据质量差"
        ],
        "answer": "A. 过拟合",
        "keywords": ["过拟合", "模型表现", "泛化"],
        "explanation": "过拟合意味着模型过于复杂，以至于在新数据上无法泛化，导致表现不佳。"
    },
    {
        "question": "一家公司希望通过访问外部信息来提高大型语言模型的响应质量，哪种方法所需的开发工作量最少？",
        "options": [
            "A. 小样本学习（Few-shot Learning）",
            "B. 零样本学习（Zero-shot Learning）",
            "C. 检索增强生成（RAG）",
            "D. 微调（Fine-tuning）"
        ],
        "answer": "C. 检索增强生成（RAG）",
        "keywords": ["外部信息", "响应质量", "开发工作量"],
        "explanation": "检索增强生成（RAG）能够在提示中整合外部信息，减少开发工作量并提高生成结果的准确性。"
    },
    {
        "question": "一个模型已被训练识别手写数字，但准确率不高。专家建议增加 Epoch 值。在机器学习中，Epoch 是什么？",
        "options": [
            "A. 测量模型在训练期间的准确性",
            "B. 模型通过整个训练数据集的一次遍历",
            "C. 将数据集划分为训练集和测试集的过程",
            "D. 神经网络中的层数"
        ],
        "answer": "B. 模型通过整个训练数据集的一次遍历",
        "keywords": ["Epoch", "手写数字", "准确率"],
        "explanation": "Epoch 是指模型完整地遍历一次训练数据集的过程。增加 Epoch 可以提高模型的学习效果。"
    },
    {
        "question": "在机器学习模型中，以下哪一项被认为是超参数？",
        "options": [
            "A. 神经网络的权重",
            "B. 优化算法的学习率",
            "C. 激活函数的输出",
            "D. 模型的预测结果"
        ],
        "answer": "B. 优化算法的学习率",
        "keywords": ["机器学习", "超参数", "学习率"],
        "explanation": "学习率是调整模型在训练过程中步伐大小的超参数。"
    },
    {
        "question": "一个模型在输入稍微改变时，仍然给出非常相似的输出。可以调整哪个推理时间参数以增加创造性？",
        "options": [
            "A. 学习率",
            "B. 批次大小",
            "C. 温度",
            "D. Epoch"
        ],
        "answer": "C. 温度",
        "keywords": ["推理时间参数", "创造性"],
        "explanation": "温度控制生成时的随机性，更高的温度增加随机性和多样性。"
    },
    {
        "question": "您正在评估语言生成模型在文本生成相关任务中的质量。哪个评估指标最能衡量其与人类书写文本的语义相似度？",
        "options": [
            "A. BERT Score",
            "B. BLEU",
            "C. Perplexity",
            "D. ROUGE"
        ],
        "answer": "A. BERT Score",
        "keywords": ["语言生成模型", "语义相似度", "评估指标"],
        "explanation": "BERT Score 使用预训练语言模型计算文本间的语义相似度，是衡量生成文本与参考文本的语义一致性的重要工具。"
    },
    {
        "question": "一名开发人员正在设计 AI 系统，需要一个提供全面工具来分析和解释模型预测的解决方案。哪项 AWS 服务专门用于提高透明度和可解释性？",
        "options": [
            "A. SageMaker Clarify",
            "B. SageMaker Debugger",
            "C. SageMaker Autopilot",
            "D. SageMaker Data Wrangler"
        ],
        "answer": "A. SageMaker Clarify",
        "keywords": ["AI 系统", "透明度", "可解释性"],
        "explanation": "SageMaker Clarify 提供分析模型预测和检测偏见的工具，是提高模型透明度和可解释性的关键服务。"
    },
    {
        "question": "一家公司计划训练并构建自己的基础模型，这种方法与使用预训练基础模型相比有什么潜在缺点？(select two)",
        "options": [
            "A. 更复杂的实施过程",
            "B. 性能降低",
            "C. 更高的错觉风险",
            "D. 增加的开发成本"
        ],
        "answer": ["A. 更复杂的实施过程","D. 增加的开发成本"],
        "keywords": ["基础模型", "训练", "构建", "缺点"],
        "explanation": "训练自己的基础模型通常涉及复杂的实施过程和高昂的开发成本，因此建议根据需求权衡选择。"
    },
    {
        "question": "一家公司希望使用现有的流行预训练 AI 模型生成内容，但没有丰富的 AI 专业知识，且不想自行管理模型。哪种 AWS 服务最适合他们的需求？",
        "options": [
            "A. Amazon Textract",
            "B. Amazon Comprehend",
            "C. Amazon Bedrock",
            "D. Amazon SageMaker"
        ],
        "answer": "C. Amazon Bedrock",
        "keywords": ["预训练 AI 模型", "生成内容", "无需管理"],
        "explanation": "Amazon Bedrock 提供对预训练基础模型的访问，适合无需大量技术知识的用户。"
    },
    {
        "question": "要微调模型以响应某种格式和风格的问题，最适合的训练数据类型是什么？",
        "options": [
            "A. 列格式数据集",
            "B. 卷标数据",
            "C. 转录日志",
            "D. 包含提示和回应的文本对"
        ],
        "answer": "D. 包含提示和回应的文本对",
        "keywords": ["微调模型", "训练数据", "格式", "风格"],
        "explanation": "包含提示和回应的文本对能够有效训练模型以生成符合特定格式和风格的输出。"
    },
    {
        "question": "公司需要记录 Amazon Bedrock 的 API 调用信息以确保合规性，包括 API 调用的详细信息、用户及时间戳。哪项 AWS 服务可以帮助他们完成此操作？",
        "options": [
            "A. CloudTrail",
            "B. CloudWatch",
            "C. IAM",
            "D. Security Hub"
        ],
        "answer": "A. CloudTrail",
        "keywords": ["API 调用", "合规性", "记录"],
        "explanation": "CloudTrail 提供 AWS 服务 API 调用的详细记录，是确保合规性的重要工具。"
    },
    {
        "question": "一个数据科学团队希望提高模型性能，他们想增加训练数据的数量和多样性，并调整算法的学习率。哪组 ML 流程步骤可以满足这些要求？(select two)",
        "options": [
            "A. 数据增强",
            "B. 模型监控",
            "C. 特征工程",
            "D. 超参数调整"
        ],
        "answer": ["A. 数据增强","D. 超参数调整"],
        "keywords": ["模型性能", "数据多样性", "学习率"],
        "explanation": "数据增强增加训练数据的多样性，而超参数调整优化学习率，从而提高模型性能。"
    },
    {
        "question": "一家公司希望确保其 Amazon Bedrock 驱动的应用生成的内容符合道德准则，避免有害或冒犯性内容。哪项 AWS 服务可以帮助他们实现这些安全措施？",
        "options": [
            "A. SageMaker",
            "B. Comprehend",
            "C. Textract",
            "D. Bedrock Guardrails"
        ],
        "answer": "D. Bedrock Guardrails",
        "keywords": ["内容生成", "道德准则", "安全措施"],
        "explanation": "Bedrock Guardrails 通过预防机制确保生成内容符合道德和安全标准。"
    },
    {
        "question": "公司正在 AWS 上使用 Amazon SageMaker 训练机器学习模型，其数据集存储在 S3 中且包含敏感的客户信息。如何确保在训练模型之前移除或匿名化数据中的敏感信息？(select two)",
        "options": [
            "A. 使用 S3 加密来保护静态数据",
            "B. 使用 Amazon Macie 识别数据集中敏感信息",
            "C. 使用 S3 访问控制限制授权人员访问",
            "D. 实施数据屏蔽技术来替换敏感信息"
        ],
        "answer": ["B. 使用 Amazon Macie 识别数据集中敏感信息","D. 实施数据屏蔽技术来替换敏感信息"],
        "keywords": ["敏感信息", "数据匿名化", "模型训练"],
        "explanation": "通过 Amazon Macie 识别敏感信息并使用数据屏蔽技术匿名化，确保客户数据的安全性。"
    },
    {
        "question": "一家公司希望使用生成式 AI 为其产品创建营销标语。为什么公司需要仔细审查所有生成的标语？",
        "options": [
            "A. 生成式 AI 可能生成过长且难以记住的标语",
            "B. 生成式 AI 可能难以捕捉公司的独特品牌形象",
            "C. 生成式 AI 可能生成不当或误导性的标语",
            "D. 生成式 AI 可能需要大量训练数据来生成有效的标语"
        ],
        "answer": "C. 生成式 AI 可能生成不当或误导性的标语",
        "keywords": ["生成式 AI", "营销标语", "审查"],
        "explanation": "生成式 AI 有可能生成带有偏见或误导性的内容，因此需要人工审查以确保适当性和质量。"
    },
    {
        "question": "您的公司正在 EC2 实例上训练机器学习模型，担心模型的安全性并希望识别基础设施中的潜在漏洞。哪项 AWS 服务可以帮助您扫描 EC2 实例的漏洞？",
        "options": [
            "A. AWS X-Ray",
            "B. Amazon CloudWatch",
            "C. Amazon Inspector",
            "D. AWS Config"
        ],
        "answer": "C. Amazon Inspector",
        "keywords": ["EC2", "漏洞扫描", "安全性"],
        "explanation": "Amazon Inspector 是一种安全服务，可帮助识别 EC2 实例中的潜在漏洞。"
    },
    {
        "question": "一个机器学习模型在城市地区的申请人中表现更佳，因为训练数据中有更多来自城市地区的批准样本。这是哪种类型的偏见的例子？",
        "options": [
            "A. 抽样偏差",
            "B. 算法偏差",
            "C. 观察者偏差",
            "D. 时间偏差"
        ],
        "answer": "A. 抽样偏差",
        "keywords": ["机器学习模型", "城市地区", "偏见"],
        "explanation": "抽样偏差发生在训练数据不具备全面代表性时，例如数据集中城市地区的样本过多。"
    },
    {
        "question": "在具有多个用户之间关系的社交网络数据集中，哪种机器学习算法最适合将这些相互关联的关系分类到预定义的类别中？",
        "options": [
            "A. 线性回归",
            "B. 判定树",
            "C. 图神经网络（Graph Neural Networks）",
            "D. 逻辑回归"
        ],
        "answer": "C. 图神经网络（Graph Neural Networks）",
        "keywords": ["社交网络", "用户关系", "分类"],
        "explanation": "图神经网络能够有效处理互相关联的数据并捕捉节点之间的关系，是分析社交网络的最佳算法。"
    },
    {
        "question": "一个机器人被指派要在迷宫中找到目标。哪种机器学习范式最适合训练机器人通过自学和试错找到最佳路径？",
        "options": [
            "A. 监督学习",
            "B. 无监督学习",
            "C. 随机学习",
            "D. 强化学习"
        ],
        "answer": "D. 强化学习",
        "keywords": ["机器人", "迷宫", "最佳路径"],
        "explanation": "强化学习通过奖励和惩罚机制，让机器人在试错过程中逐步找到解决问题的最佳策略。"
    },
    {
        "question": "一位研究人员希望使一个预训练的机器学习模型在新的特定领域任务上表现良好，但只有有限的标记数据。以下哪种方法最有效且最合适？",
        "options": [
            "A. 使用额外的未标记数据继续预训练",
            "B. 使用来自新领域的标记数据进行微调",
            "C. 使用预训练模型而不做进一步调整",
            "D. 使用新的标记数据从头开始训练"
        ],
        "answer": "B. 使用来自新领域的标记数据进行微调",
        "keywords": ["预训练模型", "特定领域", "标记数据"],
        "explanation": "微调能够有效利用预训练模型，适用于数据较少但需要适应新领域任务的情境。"
    },
    {
        "question": "如果您是一家具有不稳定工作负载的小型初创公司，并希望在 Amazon Bedrock 上实验不同的基础模型，哪种计价模式最适合您？",
        "options": [
            "A. 按需模式",
            "B. 预置吞吐量",
            "C. 模型定制",
            "D. 自定义合同"
        ],
        "answer": "A. 按需模式",
        "keywords": ["初创公司", "工作负载", "计价模式"],
        "explanation": "按需模式按使用量计费，适合工作负载不稳定的小型初创公司，避免过高的固定成本。"
    },
    {
        "question": "在自然语言处理的背景下，以下哪项是用于表示单词或子词的基本单位？",
        "options": [
            "A. 标记（Token）",
            "B. 向量嵌入（Vector Embedding）",
            "C. N-gram",
            "D. 词汇表"
        ],
        "answer": "A. 标记（Token）",
        "keywords": ["自然语言处理", "单词", "子词", "基本单位"],
        "explanation": "标记是 NLP 中的基本单位，通常表示单词或子词，用于模型的输入和输出处理。"
    },
    {
        "question": "开发人员正在创建一个预测客户流失的系统。为了确保透明性，他们需要记录有关模型的关键细节。哪项 AWS 工具最适合此任务？",
        "options": [
            "A. Amazon SageMaker Clarify",
            "B. AWS AI 服务卡",
            "C. SageMaker 模型卡",
            "D. SageMaker JumpStart"
        ],
        "answer": "C. SageMaker 模型卡",
        "keywords": ["客户流失", "透明性", "模型细节"],
        "explanation": "SageMaker 模型卡可用于记录和共享模型的关键信息，有助于提升透明性。"
    },
    {
        "question": "工程师正在训练一个机器学习模型，以防止欠拟合或过拟合，应如何对模型进行数据训练？",
        "options": [
            "A. 高偏差和高方差",
            "B. 低偏差和低方差",
            "C. 高偏差和低方差",
            "D. 低偏差和高方差"
        ],
        "answer": "B. 低偏差和低方差",
        "keywords": ["欠拟合", "过拟合", "数据训练"],
        "explanation": "低偏差和低方差表示模型既能够很好地学习训练数据，又能在新数据上表现良好。"
    },
    {
        "question": "您正在为特定领域定制大型语言模型，哪种方法最有效地调整模型的知识和准确性以适应此领域？",
        "options": [
            "A. 微调",
            "B. 少样本学习（Few-shot Learning）",
            "C. 检索增强生成（RAG）",
            "D. 零样本学习（Zero-shot Learning）"
        ],
        "answer": "A. 微调",
        "keywords": ["大型语言模型", "领域定制", "调整知识"],
        "explanation": "微调可以在特定领域数据上进一步训练模型，提高知识的准确性和适应性。"
    },
    {
        "question": "以下哪项是大型语言模型的“幻觉”现象的例子？",
        "options": [
            "A. 过拟合",
            "B. 欠拟合",
            "C. 生成错误或误导性信息",
            "D. 偏见"
        ],
        "answer": "C. 生成错误或误导性信息",
        "keywords": ["大型语言模型", "幻觉", "误导性信息"],
        "explanation": "大型语言模型有时会生成不真实或无意义的内容，这种现象被称为“幻觉”。"
    },
    {
        "question": "由 Amazon 开发并可在 Bedrock 上使用的基础模型是哪一个？",
        "options": [
            "A. Amazon Titan",
            "B. Lex",
            "C. Polly",
            "D. Connect"
        ],
        "answer": "A. Amazon Titan",
        "keywords": ["Amazon", "Bedrock", "基础模型"],
        "explanation": "Amazon Titan 是由 Amazon 开发的基础模型，可在 Bedrock 上使用。"
    },
    {
        "question": "以下哪些算法常用于机器学习中的分类任务？(select two)",
        "options": [
            "A. 支持向量机（SVM）",
            "B. XGBoost",
            "C. K-Means",
            "D. Mean Shift"
        ],
        "answer": ["A. 支持向量机（SVM）","B. XGBoost"],
        "keywords": ["机器学习", "分类任务", "算法"],
        "explanation": "支持向量机和 XGBoost 是常见的分类算法，而 K-Means 和 Mean Shift 是聚类算法。"
    },
    {
        "question": "面对大规模数据集且延迟不是关键因素，哪种 SageMaker 模型推理类型最适合提供成本效益高的预测？",
        "options": [
            "A. 实时推理",
            "B. 批次推理",
            "C. 按需无服务器推理",
            "D. 异步推理"
        ],
        "answer": "B. 批次推理",
        "keywords": ["大规模数据集", "延迟", "成本效益"],
        "explanation": "批次推理适合处理大量数据，同时具有较低的成本，适用于延迟要求不高的场景。"
    },
    {
        "question": "Amazon CodeWhisperer 的主要目的为何？",
        "options": [
            "A. 管理 AWS 基础设施",
            "B. 协助开发人员进行编程任务和查询",
            "C. 优化数据库性能",
            "D. 自动化软件测试"
        ],
        "answer": "B. 协助开发人员进行编程任务和查询",
        "keywords": ["Amazon CodeWhisperer", "编程任务", "查询"],
        "explanation": "Amazon CodeWhisperer 是一种 AI 工具，设计用于帮助开发人员完成编程任务和代码查询。"
    },
    {
        "question": "“请解释为何一个错误的说法是真的，尽管通常被认为是错的。”这种提示攻击属于哪种类型？",
        "options": [
            "A. 越狱攻击",
            "B. 提示中毒",
            "C. 对抗性提示",
            "D. 微调"
        ],
        "answer": "C. 对抗性提示",
        "keywords": ["提示攻击", "对抗性提示", "错误说法"],
        "explanation": "对抗性提示通过利用模型弱点诱导其生成错误或意料外的响应。"
    },
    {
        "question": "您正在构建一个文本摘要工具，哪个评估指标最能衡量其捕捉原文要点的效果？",
        "options": [
            "A. BERT Score",
            "B. ROUGE",
            "C. 字错误率（WER）",
            "D. BLEU"
        ],
        "answer": "B. ROUGE",
        "keywords": ["文本摘要", "评估指标", "原文要点"],
        "explanation": "ROUGE 专为评估文本摘要设计，能够衡量生成摘要与原文的相似程度。"
    },
    {
        "question": "一个生成 AI 的客服代理无法准确辨识客户意图，您可以使用哪种格式的训练数据来提升其性能？",
        "options": [
            "A. 客户讯息和客户意图",
            "B. 客户讯息和代理响应",
            "C. 客户意图和代理响应",
            "D. 代理响应和客户意图"
        ],
        "answer": "A. 客户讯息和客户意图",
        "keywords": ["生成 AI", "客服代理", "训练数据"],
        "explanation": "客户讯息和客户意图的组合能有效训练模型，提升客服代理对客户意图的识别能力。"
    },
    {
        "question": "用户通常如何被收费使用基础模型(select two)？",
        "options": [
            "A. 输入的标记数量",
            "B. 输出的标记数量",
            "C. 模型架构",
            "D. 推理延迟"
        ],
        "answer": ["A. 输入的标记数量","B. 输出的标记数量"],
        "keywords": ["基础模型", "收费模式", "标记数量"],
        "explanation": "基础模型的使用成本通常按输入和输出的标记数量计算。"
    },
    {
        "question": "哪项 AWS AI 服务可以从非结构化文本（例如临床笔记和医疗记录）中提取健康数据？",
        "options": [
            "A. Amazon Comprehend Medical",
            "B. Amazon Transcribe Medical",
            "C. Amazon HealthLake",
            "D. Amazon Rekognition"
        ],
        "answer": "A. Amazon Comprehend Medical",
        "keywords": ["非结构化文本", "健康数据", "提取"],
        "explanation": "Amazon Comprehend Medical 是专为提取医疗文本信息设计的服务，适用于非结构化数据。"
    },
    {
        "question": "哪种类型的机器学习模型专门设计用于生成与现有数据相似的新数据？",
        "options": [
            "A. 自编码器（Autoencoder）",
            "B. 生成对抗网络（GAN）",
            "C. 判定树",
            "D. 支持向量机（SVM）"
        ],
        "answer": "B. 生成对抗网络（GAN）",
        "keywords": ["机器学习", "生成新数据", "GAN"],
        "explanation": "生成对抗网络（GAN）是一种生成模型，能够创建与现有数据分布相似的全新数据。"
    },
    {
        "question": "用户将使用长提示来向大型语言模型提问，选择 LLM 时应考虑哪个关键方面？",
        "options": [
            "A. 推理延迟",
            "B. 最大上下文窗口",
            "C. 模型大小",
            "D. 训练数据"
        ],
        "answer": "B. 最大上下文窗口",
        "keywords": ["大型语言模型", "长提示", "上下文窗口"],
        "explanation": "较大的上下文窗口可以处理更多信息，是应对长提示的关键因素。"
    },
    {
        "question": "Amazon SageMaker Feature Store 的主要用途是什么？",
        "options": [
            "A. 自动训练和部署机器学习模型",
            "B. 存储和管理机器学习工作流的特征",
            "C. 提供预训练机器学习模型的市场",
            "D. 优化 SageMaker 训练任务的性能"
        ],
        "answer": "B. 存储和管理机器学习工作流的特征",
        "keywords": ["SageMaker Feature Store", "特征管理", "机器学习"],
        "explanation": "Feature Store 是 SageMaker 提供的特征管理服务，用于存储和共享机器学习的特征数据。"
    },
    {
        "question": "一家医疗保健机构正在开发一个 AI 驱动的诊断工具，以帮助早期检测罕见疾病。就合规性而言，以下哪项最不相关？",
        "options": [
            "A. 确保 AI 系统对某些患者群体不存偏见",
            "B. 最小化 AI 系统的运营费用",
            "C. 确保 AI 系统的决策过程透明",
            "D. 防止 AI 系统被用于未经授权的用途"
        ],
        "answer": "B. 最小化 AI 系统的运营费用",
        "keywords": ["AI 诊断工具", "合规性", "运营费用"],
        "explanation": "合规性主要关注公平性、透明性和安全性，而运营费用与合规性无直接关系。"
    },
    {
        "question": "您是一家大型企业，拥有大量分散在各内部系统中的非结构化数据，想为员工提供一个强大的搜索工具，以理解自然语言查询并返回准确、相关的结果。哪项 AWS 服务最适合满足此需求？",
        "options": [
            "A. Amazon Redshift",
            "B. Amazon Lex",
            "C. Amazon Kendra",
            "D. Amazon DynamoDB"
        ],
        "answer": "C. Amazon Kendra",
        "keywords": ["非结构化数据", "自然语言查询", "搜索工具"],
        "explanation": "Amazon Kendra 是一种强大的搜索服务，支持自然语言查询并返回相关结果。"
    },
    {
        "question": "一名数据科学家正进行一个项目，该项目需要快速构建原型并使用各种机器学习算法进行实验。哪项 AWS 服务最适合此任务？",
        "options": [
            "A. Amazon SageMaker Ground Truth",
            "B. Amazon EC2",
            "C. Amazon SageMaker Autopilot",
            "D. Amazon Bedrock"
        ],
        "answer": "C. Amazon SageMaker Autopilot",
        "keywords": ["快速构建原型", "机器学习算法", "实验"],
        "explanation": "SageMaker Autopilot 能自动完成模型的构建、训练和部署，适合快速原型开发。"
    },
    {
        "question": "一家大型公司希望为销售经理创建一个应用程序，能够进行推理、执行多步骤任务并从企业数据中提供有见解的回应。哪项 AWS 服务最适合此任务？",
        "options": [
            "A. Amazon Lex",
            "B. SageMaker",
            "C. Bedrock Knowledge Bases",
            "D. Bedrock Agents"
        ],
        "answer": "D. Bedrock Agents",
        "keywords": ["应用程序", "推理", "多步骤任务"],
        "explanation": "Bedrock Agents 支持基于企业数据的多步骤推理任务，是构建智能应用程序的理想选择。"
    },
    {
        "question": "一家公司希望分析客户评论，以识别常见主题和情绪。哪项 AWS 服务可以帮助公司达到此目标？",
        "options": [
            "A. Amazon Connect",
            "B. Amazon Comprehend",
            "C. Amazon Translate",
            "D. Amazon Transcribe"
        ],
        "answer": "B. Amazon Comprehend",
        "keywords": ["客户评论", "主题识别", "情绪分析"],
        "explanation": "Amazon Comprehend 能从文本中提取主题和情绪，是分析客户评论的最佳工具。"
    },
    {
        "question": "一家公司希望将数据从一种格式转换为另一种格式，以便进行机器学习任务。哪项 AWS 服务最适合进行此类数据转换？",
        "options": [
            "A. AWS Glue",
            "B. Amazon Translate",
            "C. AWS Config",
            "D. Amazon Kinesis"
        ],
        "answer": "A. AWS Glue",
        "keywords": ["数据格式转换", "机器学习", "ETL"],
        "explanation": "AWS Glue 是一项完全托管的 ETL 服务，可轻松实现数据格式转换。"
    },
    {
        "question": "一家公司希望为实时推理部署一个训练好的机器学习模型。哪项 AWS 服务最适合此用途？",
        "options": [
            "A. Amazon SageMaker JumpStart",
            "B. Amazon Personalize",
            "C. Amazon EC2",
            "D. SageMaker Endpoints"
        ],
        "answer": "D. SageMaker Endpoints",
        "keywords": ["实时推理", "模型部署", "SageMaker"],
        "explanation": "SageMaker Endpoints 专为实时推理设计，可部署训练好的模型以实时处理预测请求。"
    },
    {
        "question": "一家公司已部署一个用于客户情绪分析的机器学习模型。为了确保模型的准确性和可靠性，应使用哪些 AWS 服务进行监控和人工审查(select two)？",
        "options": [
            "A. Amazon Bedrock",
            "B. SageMaker Model Monitor",
            "C. SageMaker Ground Truth",
            "D. Amazon A2I"
        ],
        "answer": ["B. SageMaker Model Monitor","D. Amazon A2I"],
        "keywords": ["情绪分析", "监控", "人工审查"],
        "explanation": "SageMaker Model Monitor 可持续监控模型性能，而 Amazon A2I 支持在机器学习工作流中引入人工审查。"
    },
    {
        "question": "一位机器学习专家正在 Amazon SageMaker 上对一个大型深度学习模型进行训练，但单个 GPU 无法高效处理此任务。哪个 SageMaker 功能可以帮助优化大模型和大数据集的训练过程？",
        "options": [
            "A. 增量训练",
            "B. 超参数调整",
            "C. 管道模式（Pipe Mode）",
            "D. 模型并行"
        ],
        "answer": "D. 模型并行",
        "keywords": ["深度学习", "大模型", "SageMaker"],
        "explanation": "模型并行将大模型分割到多个 GPU 或实例上处理，优化了大数据集的训练过程。"
    },
    {
        "question": "您正在处理包含大量特征的数据集，为了提升模型性能和计算效率，您需要在不丢失重要信息的情况下简化数据。哪种技术最有效？",
        "options": [
            "A. 降维",
            "B. 特征工程",
            "C. 数据增强",
            "D. 数据清理"
        ],
        "answer": "A. 降维",
        "keywords": ["数据特征", "简化数据", "降维"],
        "explanation": "降维技术通过减少特征数量，同时保留关键信息，从而提升模型性能和效率。"
    },
    {
        "question": "您希望根据文本描述生成高质量的图像，哪种 AI 模型最适合生成任务并能产生高质量、多样化的输出？",
        "options": [
            "A. 生成对抗网络（GAN）",
            "B. 循环神经网络（RNN）",
            "C. 卷积神经网络（CNN）",
            "D. 稳定扩散（Stable Diffusion）"
        ],
        "answer": "D. 稳定扩散（Stable Diffusion）",
        "keywords": ["文本描述", "图像生成", "Stable Diffusion"],
        "explanation": "Stable Diffusion 是一种强大的图像生成模型，可基于文本描述生成高质量、多样化的图像。"
    },
    {
        "question": "一家公司有一个系统可以从产品数据生成向量嵌入，他们希望提高寻找相似产品的速度和准确性。哪项 AWS 服务最适合实现向量搜索以优化系统？(select two plus one)",
        "options": [
            "A. OpenSearch Service",
            "B. Redshift",
            "C. Neptune",
            "D. DocumentDB"
        ],
        "answer": ["A. OpenSearch Service","C. Neptune","D. DocumentDB"],
        "keywords": ["向量嵌入", "相似产品", "向量搜索"],
        "explanation": "OpenSearch Service、Neptune 和 DocumentDB 都支持向量搜索，可优化寻找相似产品的效率。"
    },
    {
        "question": "某银行每天收到大量贷款申请，贷款处理团队手动从这些申请中提取信息，这非常耗时。使用 AI 工具来自动化此过程的哪项 AWS 服务会有帮助？",
        "options": [
            "A. Amazon Rekognition",
            "B. Textract",
            "C. Translate",
            "D. Transcribe"
        ],
        "answer": "B. Textract",
        "keywords": ["贷款申请", "信息提取", "自动化"],
        "explanation": "Textract 可从扫描的文档中提取文本和数据，显著减少手动操作的时间和工作量。"
    },
    {
        "question": "一家医疗公司希望开发一个机器学习模型，用于根据各种健康指标预测患者发展糖尿病的可能性。以下哪项指针最适合评估该模型的性能？(select two)",
        "options": [
            "A. 准确率",
            "B. 精确率",
            "C. F1 分数",
            "D. 召回率（灵敏度）",
            "E. ROC 曲线下面积（AUC）"
        ],
    "answer": ["D. 召回率（灵敏度）","E. ROC 曲线下面积（AUC）"],
        "keywords": ["医疗模型", "性能评估", "糖尿病预测"],
        "explanation": "召回率和 AUC 适用于评估分类模型的性能，特别是在医疗场景中。"
    },
    {
        "question": "某组织已在大型一般图像数据集上训练了一个深度学习模型，现在他们希望使用该模型来分类医学图像，但数据集较小。哪种机器学习技术最适合这种情境？",
        "options": [
            "A. 强化学习",
            "B. 迁移学习",
            "C. 监督学习",
            "D. 无监督学习"
        ],
        "answer": "B. 迁移学习",
        "keywords": ["图像分类", "迁移学习", "小数据集"],
        "explanation": "迁移学习能够利用已有模型的知识，在新的医学图像分类任务中实现高效学习。"
    },
    {
        "question": "您正在 AWS 上构建一个机器学习模型，并希望安全地与第三方合作伙伴共享该模型。哪项 AWS 服务可用于在您的 VPC 和合作伙伴的 VPC 之间建立私有连接，确保数据不暴露在公网上？",
        "options": [
            "A. Direct Connect",
            "B. PrivateLink",
            "C. Transit Gateway",
            "D. VPN"
        ],
        "answer": "B. PrivateLink",
        "keywords": ["VPC", "私有连接", "数据安全"],
        "explanation": "PrivateLink 支持在 VPC 之间建立安全的私有连接，确保数据隐私。"
    },
    {
        "question": "您正在 AWS SageMaker 上使用敏感的客户数据进行模型训练。根据 AWS 的共享责任模型，以下哪项主要由您负责？",
        "options": [
            "A. 确保 SageMaker 基础设施的安全",
            "B. 保护 SageMaker 实例的操作系统",
            "C. 确保存储在 S3 中的客户数据的安全",
            "D. 为 AWS SageMaker 软件打补丁"
        ],
        "answer": "C. 确保存储在 S3 中的客户数据的安全",
        "keywords": ["共享责任模型", "客户数据", "安全性"],
        "explanation": "根据共享责任模型，AWS 负责基础设施的安全，客户负责保护自己的数据安全。"
    },
    {
        "question": "在实施生成式 AI 安全范围矩阵时，以下哪项因素应用于评估与生成式 AI 项目相关的风险？",
        "options": [
            "A. 模型的计算效率",
            "B. 用于训练模型的数据敏感性",
            "C. 推理延迟",
            "D. 模型的参数数量"
        ],
        "answer": "B. 用于训练模型的数据敏感性",
        "keywords": ["生成式 AI", "风险评估", "数据敏感性"],
        "explanation": "数据敏感性是评估生成式 AI 项目风险的重要因素，直接影响隐私和安全。"
    }
]